{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvEkx5iA1rSfgKPHm1w2zC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajiroZ/for_git_study/blob/master/ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_xZ76PMFfca",
        "outputId": "3ff17ce2-99cf-4cc9-a29e-44f494f32cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
            "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
            "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
            "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
            "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
            "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
            "\n",
            "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
            "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
            "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
            "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
            "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
            "\n",
            "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0         2   2008        WD         Normal     208500  \n",
            "1         5   2007        WD         Normal     181500  \n",
            "2         9   2008        WD         Normal     223500  \n",
            "3         2   2006        WD        Abnorml     140000  \n",
            "4        12   2008        WD         Normal     250000  \n",
            "...     ...    ...       ...            ...        ...  \n",
            "1455      8   2007        WD         Normal     175000  \n",
            "1456      2   2010        WD         Normal     210000  \n",
            "1457      5   2010        WD         Normal     266500  \n",
            "1458      4   2010        WD         Normal     142125  \n",
            "1459      6   2008        WD         Normal     147500  \n",
            "\n",
            "[1460 rows x 81 columns]\n",
            "X_train shape: (1168, 2)\n",
            "y_train shape: (1168,)\n",
            "X_valid shape: (292, 2)\n",
            "y_valid shape: (292,)\n"
          ]
        }
      ],
      "source": [
        "# train.csvの目的変数としてSalePrice, 説明変数としてGrLivAreaとYearBuiltを抽出\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/train.csv')\n",
        "\n",
        "print(df)\n",
        "\n",
        "# 目的変数と説明変数の選択\n",
        "target_variable = 'SalePrice'\n",
        "explanatory_variables = ['GrLivArea', 'YearBuilt']\n",
        "\n",
        "# 欠損値を含む行を削除\n",
        "df = df.dropna(subset=[target_variable] + explanatory_variables)\n",
        "\n",
        "# データの分割\n",
        "X = df[explanatory_variables]\n",
        "y = df[target_variable]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# 分割後のデータの確認 (任意)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"y_valid shape:\", y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題1】ブレンディングのスクラッチ実装\n",
        "\n"
      ],
      "metadata": {
        "id": "CJQuE7ZNJlx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 線形回帰、SVM、決定木、ニューラルネットワークそれぞれ単一のモデルでのMSEを求める\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/train.csv')\n",
        "\n",
        "# 目的変数と説明変数の選択\n",
        "target_variable = 'SalePrice'\n",
        "explanatory_variables = ['GrLivArea', 'YearBuilt']\n",
        "\n",
        "# 欠損値を含む行を削除\n",
        "df = df.dropna(subset=[target_variable] + explanatory_variables)\n",
        "\n",
        "# データの分割\n",
        "X = df[explanatory_variables]\n",
        "y = df[target_variable]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "# 線形回帰\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_valid)\n",
        "mse_lr = mean_squared_error(y_valid, y_pred_lr)\n",
        "print(f\"Linear Regression MSE: {mse_lr}\")\n",
        "\n",
        "# SVM\n",
        "svr = SVR()\n",
        "svr.fit(X_train, y_train)\n",
        "y_pred_svr = svr.predict(X_valid)\n",
        "mse_svr = mean_squared_error(y_valid, y_pred_svr)\n",
        "print(f\"SVM MSE: {mse_svr}\")\n",
        "\n",
        "# 決定木\n",
        "dt = DecisionTreeRegressor(random_state=0)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_valid)\n",
        "mse_dt = mean_squared_error(y_valid, y_pred_dt)\n",
        "print(f\"Decision Tree MSE: {mse_dt}\")\n",
        "\n",
        "# ニューラルネットワーク\n",
        "mlp = MLPRegressor(random_state=0, max_iter=1000) # max_iterを増やして収束を確認\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = mlp.predict(X_valid)\n",
        "mse_mlp = mean_squared_error(y_valid, y_pred_mlp)\n",
        "print(f\"MLPRegressor MSE: {mse_mlp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOPZ8J4CK8sA",
        "outputId": "84d838de-8b0a-4db7-bd59-b23364dac0c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE: 2942066921.6721087\n",
            "SVM MSE: 7235023974.812659\n",
            "Decision Tree MSE: 3009170128.186454\n",
            "MLPRegressor MSE: 3731243284.413869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ブレンディングをスクラッチ実装する\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# モデルのインスタンス化\n",
        "model1 = LinearRegression()\n",
        "model2 = SVR()\n",
        "model3 = DecisionTreeRegressor()\n",
        "\n",
        "# モデルの学習\n",
        "model1.fit(X_train, y_train)\n",
        "model2.fit(X_train, y_train)\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "# 予測値の取得\n",
        "pred1 = model1.predict(X_valid)\n",
        "pred2 = model2.predict(X_valid)\n",
        "pred3 = model3.predict(X_valid)\n",
        "\n",
        "# ブレンディング\n",
        "# 予測値を重み付け平均で結合する\n",
        "# 重みの合計が1になるように調整\n",
        "w1 = 0.3  # LinearRegressionの重み\n",
        "w2 = 0.3  # SVRの重み\n",
        "w3 = 0.4  # DecisionTreeRegressorの重み\n",
        "\n",
        "# 重みを調整し、合計が1になることを確認\n",
        "# assert np.isclose(w1 + w2 + w3, 1.0), \"Weights must sum to 1.0\"  # 必要に応じてアサーションを追加\n",
        "\n",
        "blended_pred = w1 * pred1 + w2 * pred2 + w3 * pred3\n",
        "\n",
        "\n",
        "# 平均二乗誤差の算出\n",
        "mse = mean_squared_error(y_valid, blended_pred)\n",
        "print(f\"Blended MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZHF89u4KRL7",
        "outputId": "334bba7e-c3e8-4d47-ed00-2b5cea2de3ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blended MSE: 2736308546.3999968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: ブレンディングにあたり、ハイパーパラメータを変えたモデルの組み合わせを含める\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/train.csv')\n",
        "\n",
        "# 目的変数と説明変数の選択\n",
        "target_variable = 'SalePrice'\n",
        "explanatory_variables = ['GrLivArea', 'YearBuilt']\n",
        "\n",
        "# 欠損値を含む行を削除\n",
        "df = df.dropna(subset=[target_variable] + explanatory_variables)\n",
        "\n",
        "# データの分割\n",
        "X = df[explanatory_variables]\n",
        "y = df[target_variable]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# モデルのリストとハイパーパラメータ\n",
        "models = [\n",
        "    (LinearRegression(), {}),  # 線形回帰\n",
        "    (SVR(), {'kernel': 'rbf', 'C': 100}), # SVM (ハイパーパラメータ変更)\n",
        "    (DecisionTreeRegressor(), {'max_depth': 5, 'random_state':0}), # 決定木 (ハイパーパラメータ変更)\n",
        "    (MLPRegressor(random_state=0, max_iter=1000), {}) # ニューラルネットワーク\n",
        "]\n",
        "\n",
        "predictions = []\n",
        "for model, params in models:\n",
        "    model.set_params(**params)  # ハイパーパラメータを設定\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    predictions.append(y_pred)\n",
        "    mse = mean_squared_error(y_valid, y_pred)\n",
        "    print(f\"{model.__class__.__name__} with params {params} MSE: {mse}\")\n",
        "\n",
        "# ブレンディング (重み付き平均)\n",
        "weights = [0.25, 0.25, 0.25, 0.25] # 各モデルの重み（合計は1になるように設定）\n",
        "blended_pred = np.average(predictions, axis=0, weights=weights)\n",
        "\n",
        "mse_blended = mean_squared_error(y_valid, blended_pred)\n",
        "print(f\"Blended MSE: {mse_blended}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "755IciycL1P9",
        "outputId": "4a90a51a-00ce-4ac4-de48-821bad1935c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression with params {} MSE: 2942066921.6721087\n",
            "SVR with params {'kernel': 'rbf', 'C': 100} MSE: 6089799668.498366\n",
            "DecisionTreeRegressor with params {'max_depth': 5, 'random_state': 0} MSE: 2169961248.6656322\n",
            "MLPRegressor with params {} MSE: 3731243284.413869\n",
            "Blended MSE: 2865055788.513104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: ブレンディングに際して、入力データの前処理をPCAにしたモデルを含める\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/train.csv')\n",
        "\n",
        "# 目的変数と説明変数の選択\n",
        "target_variable = 'SalePrice'\n",
        "explanatory_variables = ['GrLivArea', 'YearBuilt']\n",
        "\n",
        "# 欠損値を含む行を削除\n",
        "df = df.dropna(subset=[target_variable] + explanatory_variables)\n",
        "\n",
        "# データの分割\n",
        "X = df[explanatory_variables]\n",
        "y = df[target_variable]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# 標準化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=1) # 主成分を1つに削減\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_valid_pca = pca.transform(X_valid_scaled)\n",
        "\n",
        "# モデルのリストとハイパーパラメータ\n",
        "models = [\n",
        "    (LinearRegression(), {}),\n",
        "    (SVR(), {'kernel': 'rbf', 'C': 100}),\n",
        "    (DecisionTreeRegressor(), {'max_depth': 5, 'random_state':0}),\n",
        "    (MLPRegressor(random_state=0, max_iter=1000), {})\n",
        "]\n",
        "\n",
        "predictions = []\n",
        "for model, params in models:\n",
        "    model.set_params(**params)\n",
        "    model.fit(X_train_pca, y_train) # PCA適用後のデータで学習\n",
        "    y_pred = model.predict(X_valid_pca) # PCA適用後のデータで予測\n",
        "    predictions.append(y_pred)\n",
        "    mse = mean_squared_error(y_valid, y_pred)\n",
        "    print(f\"{model.__class__.__name__} with params {params} MSE: {mse}\")\n",
        "\n",
        "# ブレンディング (重み付き平均)\n",
        "weights = [0.25, 0.25, 0.25, 0.25]\n",
        "blended_pred = np.average(predictions, axis=0, weights=weights)\n",
        "\n",
        "mse_blended = mean_squared_error(y_valid, blended_pred)\n",
        "print(f\"Blended MSE: {mse_blended}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqmoZJNkMxtJ",
        "outputId": "ee609f19-0794-4097-b667-ab381d5db233"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression with params {} MSE: 2913453795.88941\n",
            "SVR with params {'kernel': 'rbf', 'C': 100} MSE: 5662432108.443092\n",
            "DecisionTreeRegressor with params {'max_depth': 5, 'random_state': 0} MSE: 1857425427.152014\n",
            "MLPRegressor with params {} MSE: 37444521557.03058\n",
            "Blended MSE: 5395012967.675472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "どのブレンディングでも、単独で最もMSEが短い線形回帰よりも精度がよくなった。\n",
        "\n",
        "ブレンディングするモデルの数によるものとは限らないが、標準化やPCAなどの前処理を組み込んだモデルが含まれるブレンディングは、特に精度が高いことが分かった。"
      ],
      "metadata": {
        "id": "CG34neDJNi8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題2】バギングのスクラッチ実装"
      ],
      "metadata": {
        "id": "he8iPotoOXHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# バギングをスクラッチ実装し、精度を上げる\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# データの読み込みと前処理\n",
        "df = pd.read_csv('/train.csv')\n",
        "target_variable = 'SalePrice'\n",
        "explanatory_variables = ['GrLivArea', 'YearBuilt']\n",
        "df = df.dropna(subset=[target_variable] + explanatory_variables)\n",
        "X = df[explanatory_variables]\n",
        "y = df[target_variable]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# バギングの実装\n",
        "n_estimators = 10  # 決定木の数\n",
        "predictions = []\n",
        "\n",
        "for i in range(n_estimators):\n",
        "    # 「ブートストラップサンプリング」\n",
        "    bootstrap_indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
        "    X_bootstrap = X_train.iloc[bootstrap_indices]\n",
        "    y_bootstrap = y_train.iloc[bootstrap_indices]\n",
        "\n",
        "    # 決定木の学習\n",
        "    model = DecisionTreeRegressor(random_state=i) # random_stateをループごとに変更\n",
        "    model.fit(X_bootstrap, y_bootstrap)\n",
        "\n",
        "    # 予測値の取得\n",
        "    y_pred = model.predict(X_valid)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "# バギングによる予測値の平均化\n",
        "bagging_pred = np.mean(predictions, axis=0)\n",
        "\n",
        "# 平均二乗誤差の計算\n",
        "mse_bagging = mean_squared_error(y_valid, bagging_pred)\n",
        "print(f\"Bagging MSE: {mse_bagging}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_Fp84DIOWyG",
        "outputId": "80078621-7287-4bb2-a4dc-4b30ce57b7a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging MSE: 1910533246.6218002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題3】スタッキングのスクラッチ実装"
      ],
      "metadata": {
        "id": "I3lU8lFSO0Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# スタッキングをスクラッチ実装する\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/train.csv')\n",
        "\n",
        "# 目的変数と説明変数の選択\n",
        "target_variable = 'SalePrice'\n",
        "explanatory_variables = ['GrLivArea', 'YearBuilt']\n",
        "\n",
        "# 欠損値を含む行を削除\n",
        "df = df.dropna(subset=[target_variable] + explanatory_variables)\n",
        "\n",
        "# データの分割\n",
        "X = df[explanatory_variables]\n",
        "y = df[target_variable]\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "#レベル１モデル\n",
        "# モデルのリストとハイパーパラメータ\n",
        "models = [\n",
        "    LinearRegression(),\n",
        "    SVR(kernel='rbf', C=100),\n",
        "    DecisionTreeRegressor(max_depth=5, random_state=0),\n",
        "    MLPRegressor(random_state=0, max_iter=1000)\n",
        "]\n",
        "\n",
        "# 各モデルの予測値を格納するリスト\n",
        "level1_predictions = []\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_valid)\n",
        "    level1_predictions.append(y_pred)\n",
        "\n",
        "\n",
        "# レベル1の予測値を結合して新しい特徴量を作成\n",
        "level1_predictions = np.array(level1_predictions).T\n",
        "#レベル２モデル\n",
        "# スタッキングモデルの学習\n",
        "level2_model = LinearRegression()\n",
        "level2_model.fit(level1_predictions, y_valid)\n",
        "\n",
        "# レベル1モデルの検証データに対する予測値を取得\n",
        "level1_valid_predictions = []\n",
        "for model in models:\n",
        "    level1_valid_pred = model.predict(X_valid)\n",
        "    level1_valid_predictions.append(level1_valid_pred)\n",
        "level1_valid_predictions = np.array(level1_valid_predictions).T\n",
        "\n",
        "# スタッキングモデルによる予測\n",
        "stacked_predictions = level2_model.predict(level1_valid_predictions)\n",
        "\n",
        "# MSEの算出\n",
        "mse_stacked = mean_squared_error(y_valid, stacked_predictions)\n",
        "print(f\"Stacked MSE: {mse_stacked}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMZo5qkUO-li",
        "outputId": "8dcaad31-5e57-456a-9ac2-98e3c17596df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacked MSE: 2147383210.1924074\n"
          ]
        }
      ]
    }
  ]
}