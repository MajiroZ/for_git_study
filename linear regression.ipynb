{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9kTl2GwWT5eggcyRXAXXn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajiroZ/for_git_study/blob/master/linear%20regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題1】仮定関数"
      ],
      "metadata": {
        "id": "hPdQ9gU73DPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# y=ax1+b\n",
        "a = 1\n",
        "b = 2\n",
        "x1 = 3\n",
        "y = a * x1 + b\n",
        "print(y)"
      ],
      "metadata": {
        "id": "pubAp02K3pjp",
        "outputId": "e8a2f751-d84f-4dda-dc12-d8ae7d7feb7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.array([[b], [a]])\n",
        "X = np.array([[1, x1]])\n",
        "y = X@theta\n",
        "print(y)"
      ],
      "metadata": {
        "id": "piaArd_V3sji",
        "outputId": "e20bdb78-cb8b-4dd0-86c5-83896fb86eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _linear_hypothesis(self, X):\n",
        "\n",
        "    for j in range(len(self.coef_)) :\n",
        "        y += self.coef_[j] * X[:, j]\n",
        "\n",
        "    # 内積の計算\n",
        "    dot_product = np.dot(X, y)\n",
        "    return dot_product"
      ],
      "metadata": {
        "id": "MbMz4-fp3CjI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題2】最急降下法"
      ],
      "metadata": {
        "id": "iXlQNZ9RscJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _gradient_descent(self, X, error):\n",
        "    m = X.shape[0]\n",
        "    n = X.shape[1]\n",
        "\n",
        "    for j in range(n):\n",
        "        gradient = 0\n",
        "        for i in range(m):\n",
        "            gradient += (error[i]) * X[i][j]\n",
        "        self.coef_[j] = self.coef_[j] - (self.lr / m) * gradient\n",
        "\n"
      ],
      "metadata": {
        "id": "QwO9cnyRsFIK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
        "        # ハイパーパラメータを属性として記録\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.no_bias = no_bias\n",
        "        self.verbose = verbose\n",
        "        # 損失を記録する配列を用意\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        # Initialize coefficients (you might need to adjust this based on your needs)\n",
        "        self.coef_ = np.zeros(X.shape[1])\n",
        "\n",
        "        for i in range(self.iter):\n",
        "            # 1. Predict using current coefficients\n",
        "            pred = self.predict(X)\n",
        "\n",
        "            # 2. Calculate the error\n",
        "            error = pred - y\n",
        "\n",
        "            # 3. Update coefficients using gradient descent\n",
        "            self._gradient_descent(X, error)\n",
        "\n",
        "            # (Optional) Calculate and store loss if verbose is True\n",
        "            for i in range(self.iter):\n",
        "              pred = self.predict(X)  # 学習データの予測値を得る\n",
        "              self.loss[i] = self.lossfunction(pred, y)  # 学習した損失を計算して記録する\n",
        "\n",
        "              if X_val is not None and y_val is not None:\n",
        "                pred_val = self.predict(X_val)  # 検証データの予測値を得る\n",
        "                self.val_loss[i] = self.lossfunction(pred_val, y_val)  # 検証した時の損失を計算して記録する\n",
        "                error = pred - y  # 勾配降下の誤差を求める\n",
        "                self._gradient_descent(X, error)  # アプデ\n",
        "\n",
        "    def _gradient_descent(self, X, error):\n",
        "        m = X.shape[0]\n",
        "        n = X.shape[1]\n",
        "\n",
        "        for j in range(n):\n",
        "            gradient = 0\n",
        "            for i in range(m):\n",
        "                gradient += (error[i]) * X[i][j]\n",
        "            self.coef_[j] = self.coef_[j] - (self.lr / m) * gradient"
      ],
      "metadata": {
        "id": "riru2AgIG2e_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題3】推定"
      ],
      "metadata": {
        "id": "0LwYaA_WA8oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self, X):\n",
        "    if self.bias == True:\n",
        "        bias = np.ones(X.shape[0]).reshape(X.shape[0], 1)\n",
        "        X = np.hstack([bias, X])\n",
        "    pred_y = self._linear_hypothesis(X)\n",
        "    return pred_y"
      ],
      "metadata": {
        "id": "ZhR3driy_Ttq"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題4】平均二乗誤差"
      ],
      "metadata": {
        "id": "BuXw74eZCyYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE(self,y_pred, y):\n",
        "    mse = ((y_pred - y) ** 2).sum() / X.shape[0]\n",
        "    return mse"
      ],
      "metadata": {
        "id": "xXp3bK8fC5I-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題5】目的関数"
      ],
      "metadata": {
        "id": "j4pBPG4tDEt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lossfunction(self, y_pred, y):\n",
        "    mse = ((y_pred - y) ** 2).sum() / X.shape[0]\n",
        "    return mse"
      ],
      "metadata": {
        "id": "UeMXoScGGq18"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        # Initialize coefficients (you might need to adjust this based on your needs)\n",
        "        self.coef_ = np.zeros(X.shape[1])\n",
        "\n",
        "        for i in range(self.iter):\n",
        "            # 1. Predict using current coefficients\n",
        "            pred = self.predict(X)\n",
        "\n",
        "            # 2. Calculate the error\n",
        "            error = pred - y\n",
        "\n",
        "            # 3. Update coefficients using gradient descent\n",
        "            self._gradient_descent(X, error)\n",
        "\n",
        "            # (Optional) Calculate and store loss if verbose is True\n",
        "            for i in range(self.iter):\n",
        "              pred = self.predict(X)  # 学習データの予測値を得る\n",
        "              self.loss[i] = self.lossfunction(pred, y)  # 学習した損失を計算して記録する\n",
        "\n",
        "              if X_val is not None and y_val is not None:\n",
        "                pred_val = self.predict(X_val)  # 検証データの予測値を得る\n",
        "                self.val_loss[i] = self.lossfunction(pred_val, y_val)  # 検証した時の損失を計算して記録する\n",
        "                error = pred - y  # 勾配降下の誤差を求める\n",
        "                self._gradient_descent(X, error)  # アプデ"
      ],
      "metadata": {
        "id": "_GX0EvYaIJpv"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題6】学習と推定"
      ],
      "metadata": {
        "id": "LbY_3-lcIL1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class ScratchLinearRegression():\n",
        "    def __init__(self, num_iter=5000, lr=0.01, no_bias=False, verbose=False):\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.no_bias = no_bias\n",
        "        self.verbose = verbose\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "        self.coef_ = None\n",
        "\n",
        "    def _linear_hypothesis(self, X):\n",
        "        return np.dot(X, self.coef_)\n",
        "\n",
        "    def _gradient_descent(self, X, error):\n",
        "        gradient = np.dot(X.T, error) / X.shape[0]\n",
        "        self.coef_ -= self.lr * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.no_bias and X.shape[1] == self.coef_.shape[0] - 1:\n",
        "           X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        return self._linear_hypothesis(X)\n",
        "\n",
        "    def MSE(self, y_pred, y):\n",
        "        return np.mean((y_pred - y) ** 2)\n",
        "\n",
        "    def lossfunction(self, y_pred, y):\n",
        "        return self.MSE(y_pred, y)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        num_features = X.shape[1] + (not self.no_bias)\n",
        "        self.coef_ = np.random.randn(num_features) * 0.01  # Random init\n",
        "\n",
        "        if not self.no_bias:\n",
        "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "            if X_val is not None:\n",
        "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
        "\n",
        "        for i in range(self.iter):\n",
        "            pred = self.predict(X)\n",
        "            error = pred - y\n",
        "            self._gradient_descent(X, error)\n",
        "            self.loss[i] = self.lossfunction(pred, y)\n",
        "            if X_val is not None and y_val is not None:\n",
        "                pred_val = self.predict(X_val)\n",
        "                self.val_loss[i] = self.lossfunction(pred_val, y_val)\n",
        "\n",
        "            if self.verbose and i % 10 == 0:\n",
        "                print(f\"Epoch {i}, Loss: {self.loss[i]:.4f}, Val Loss: {self.val_loss[i]:.4f}\")\n",
        "\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/application_train.csv')\n",
        "\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT']\n",
        "target = 'TARGET'\n",
        "\n",
        "df = df[features + [target]].dropna()\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "# データ分割と標準化\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# モデル作成と学習\n",
        "model = ScratchLinearRegression(num_iter=5000, lr=0.01, no_bias=False, verbose=True)\n",
        "model.fit(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# 推定と評価\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.MSE(y_pred, y_test)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO_34Cy2IV47",
        "outputId": "08968403-b541-4796-8465-78500ec1e54a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0823, Val Loss: 0.0792\n",
            "Epoch 10, Loss: 0.0811, Val Loss: 0.0780\n",
            "Epoch 20, Loss: 0.0800, Val Loss: 0.0770\n",
            "Epoch 30, Loss: 0.0792, Val Loss: 0.0762\n",
            "Epoch 40, Loss: 0.0785, Val Loss: 0.0755\n",
            "Epoch 50, Loss: 0.0779, Val Loss: 0.0750\n",
            "Epoch 60, Loss: 0.0774, Val Loss: 0.0746\n",
            "Epoch 70, Loss: 0.0770, Val Loss: 0.0742\n",
            "Epoch 80, Loss: 0.0767, Val Loss: 0.0739\n",
            "Epoch 90, Loss: 0.0765, Val Loss: 0.0737\n",
            "Epoch 100, Loss: 0.0762, Val Loss: 0.0735\n",
            "Epoch 110, Loss: 0.0761, Val Loss: 0.0734\n",
            "Epoch 120, Loss: 0.0759, Val Loss: 0.0732\n",
            "Epoch 130, Loss: 0.0758, Val Loss: 0.0731\n",
            "Epoch 140, Loss: 0.0757, Val Loss: 0.0731\n",
            "Epoch 150, Loss: 0.0756, Val Loss: 0.0730\n",
            "Epoch 160, Loss: 0.0756, Val Loss: 0.0729\n",
            "Epoch 170, Loss: 0.0755, Val Loss: 0.0729\n",
            "Epoch 180, Loss: 0.0755, Val Loss: 0.0729\n",
            "Epoch 190, Loss: 0.0755, Val Loss: 0.0728\n",
            "Epoch 200, Loss: 0.0754, Val Loss: 0.0728\n",
            "Epoch 210, Loss: 0.0754, Val Loss: 0.0728\n",
            "Epoch 220, Loss: 0.0754, Val Loss: 0.0728\n",
            "Epoch 230, Loss: 0.0754, Val Loss: 0.0728\n",
            "Epoch 240, Loss: 0.0754, Val Loss: 0.0728\n",
            "Epoch 250, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 260, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 270, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 280, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 290, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 300, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 310, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 320, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 330, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 340, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 350, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 360, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 370, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 380, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 390, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 400, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 410, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 420, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 430, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 440, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 450, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 460, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 470, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 480, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 490, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 500, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 510, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 520, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 530, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 540, Loss: 0.0753, Val Loss: 0.0727\n",
            "Epoch 550, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 560, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 570, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 580, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 590, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 600, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 610, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 620, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 630, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 640, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 650, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 660, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 670, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 680, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 690, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 700, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 710, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 720, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 730, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 740, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 750, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 760, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 770, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 780, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 790, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 800, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 810, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 820, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 830, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 840, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 850, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 860, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 870, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 880, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 890, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 900, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 910, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 920, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 930, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 940, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 950, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 960, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 970, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 980, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 990, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1000, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1010, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1020, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1030, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1040, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1050, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1060, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1070, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1080, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1090, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1100, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1110, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1120, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1130, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1140, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1150, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1160, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1170, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1180, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1190, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1200, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1210, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1220, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1230, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1240, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1250, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1260, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1270, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1280, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1290, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1300, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1310, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1320, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1330, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1340, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1350, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1360, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1370, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1380, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1390, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1400, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1410, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1420, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1430, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1440, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1450, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1460, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1470, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1480, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1490, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1500, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1510, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1520, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1530, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1540, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1550, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1560, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1570, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1580, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1590, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1600, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1610, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1620, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1630, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1640, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1650, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1660, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1670, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1680, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1690, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1700, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1710, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1720, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1730, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1740, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1750, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1760, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1770, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1780, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1790, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1800, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1810, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1820, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1830, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1840, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1850, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1860, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1870, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1880, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1890, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1900, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1910, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1920, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1930, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1940, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1950, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1960, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1970, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1980, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 1990, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2000, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2010, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2020, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2030, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2040, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2050, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2060, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2070, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2080, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2090, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2100, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2110, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2120, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2130, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2140, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2150, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2160, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2170, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2180, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2190, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2200, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2210, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2220, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2230, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2240, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2250, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2260, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2270, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2280, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2290, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2300, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2310, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2320, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2330, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2340, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2350, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2360, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2370, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2380, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2390, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2400, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2410, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2420, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2430, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2440, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2450, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2460, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2470, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2480, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2490, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2500, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2510, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2520, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2530, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2540, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2550, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2560, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2570, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2580, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2590, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2600, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2610, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2620, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2630, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2640, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2650, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2660, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2670, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2680, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2690, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2700, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2710, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2720, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2730, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2740, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2750, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2760, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2770, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2780, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2790, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2800, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2810, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2820, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2830, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2840, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2850, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2860, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2870, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2880, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2890, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2900, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2910, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2920, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2930, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2940, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2950, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2960, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2970, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2980, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 2990, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3000, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3010, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3020, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3030, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3040, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3050, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3060, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3070, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3080, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3090, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3100, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3110, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3120, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3130, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3140, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3150, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3160, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3170, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3180, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3190, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3200, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3210, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3220, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3230, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3240, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3250, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3260, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3270, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3280, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3290, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3300, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3310, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3320, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3330, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3340, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3350, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3360, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3370, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3380, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3390, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3400, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3410, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3420, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3430, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3440, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3450, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3460, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3470, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3480, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3490, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3500, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3510, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3520, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3530, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3540, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3550, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3560, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3570, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3580, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3590, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3600, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3610, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3620, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3630, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3640, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3650, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3660, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3670, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3680, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3690, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3700, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3710, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3720, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3730, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3740, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3750, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3760, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3770, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3780, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3790, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3800, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3810, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3820, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3830, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3840, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3850, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3860, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3870, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3880, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3890, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3900, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3910, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3920, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3930, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3940, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3950, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3960, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3970, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3980, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 3990, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4000, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4010, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4020, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4030, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4040, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4050, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4060, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4070, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4080, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4090, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4100, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4110, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4120, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4130, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4140, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4150, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4160, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4170, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4180, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4190, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4200, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4210, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4220, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4230, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4240, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4250, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4260, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4270, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4280, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4290, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4300, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4310, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4320, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4330, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4340, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4350, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4360, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4370, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4380, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4390, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4400, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4410, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4420, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4430, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4440, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4450, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4460, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4470, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4480, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4490, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4500, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4510, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4520, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4530, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4540, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4550, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4560, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4570, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4580, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4590, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4600, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4610, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4620, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4630, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4640, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4650, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4660, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4670, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4680, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4690, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4700, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4710, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4720, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4730, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4740, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4750, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4760, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4770, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4780, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4790, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4800, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4810, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4820, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4830, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4840, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4850, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4860, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4870, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4880, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4890, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4900, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4910, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4920, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4930, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4940, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4950, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4960, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4970, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4980, Loss: 0.0753, Val Loss: 0.0728\n",
            "Epoch 4990, Loss: 0.0753, Val Loss: 0.0728\n",
            "Mean Squared Error: 0.07275174296446113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題7】学習曲線のプロット"
      ],
      "metadata": {
        "id": "t2LZ-erB9typ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# self.lossとself.val_lossに記録された損失を基に、学習曲線を表示する\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plt.plot(model.loss, label='train')\n",
        "plt.plot(model.val_loss, label='val')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "9-Q-Xe_69uZU",
        "outputId": "c9b89035-96ea-4cfe-aaf7-7354577d2ae9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題8】バイアス項の除去"
      ],
      "metadata": {
        "id": "ioA9H4afjE3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# これまでのコードからバイアス項を抜いて検証する\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ScratchLinearRegression():\n",
        "    def __init__(self, num_iter=5000, lr=0.01, no_bias=False, verbose=False):\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.no_bias = no_bias\n",
        "        self.verbose = verbose\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "        self.coef_ = None\n",
        "\n",
        "    def _linear_hypothesis(self, X):\n",
        "        return np.dot(X, self.coef_)\n",
        "\n",
        "    def _gradient_descent(self, X, error):\n",
        "        gradient = np.dot(X.T, error) / X.shape[0]\n",
        "        self.coef_ -= self.lr * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        # バイアス項なしの処理\n",
        "        return self._linear_hypothesis(X)\n",
        "\n",
        "    def MSE(self, y_pred, y):\n",
        "        return np.mean((y_pred - y) ** 2)\n",
        "\n",
        "    def lossfunction(self, y_pred, y):\n",
        "        return self.MSE(y_pred, y)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        # バイアス項なしで初期化\n",
        "        self.coef_ = np.random.randn(X.shape[1]) * 0.01\n",
        "\n",
        "        for i in range(self.iter):\n",
        "            pred = self.predict(X)\n",
        "            error = pred - y\n",
        "            self._gradient_descent(X, error)\n",
        "            self.loss[i] = self.lossfunction(pred, y)\n",
        "            if X_val is not None and y_val is not None:\n",
        "                pred_val = self.predict(X_val)\n",
        "                self.val_loss[i] = self.lossfunction(pred_val, y_val)\n",
        "\n",
        "            if self.verbose and i % 10 == 0:\n",
        "                print(f\"Epoch {i}, Loss: {self.loss[i]:.4f}, Val Loss: {self.val_loss[i]:.4f}\")\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/application_train.csv')\n",
        "\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT']\n",
        "target = 'TARGET'\n",
        "\n",
        "df = df[features + [target]].dropna()\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "# データ分割と標準化\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# モデル作成と学習（バイアス項なし）\n",
        "model = ScratchLinearRegression(num_iter=5000, lr=0.01, no_bias=True, verbose=True) # no_bias=Trueに変更\n",
        "model.fit(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# 推定と評価\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.MSE(y_pred, y_test)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plt.plot(model.loss, label='train')\n",
        "plt.plot(model.val_loss, label='val')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u9hEUAn7Wu-L",
        "outputId": "ffff51b9-a247-44ef-dabc-ff0b2d1521b9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0817, Val Loss: 0.0814\n",
            "Epoch 10, Loss: 0.0816, Val Loss: 0.0813\n",
            "Epoch 20, Loss: 0.0816, Val Loss: 0.0813\n",
            "Epoch 30, Loss: 0.0816, Val Loss: 0.0813\n",
            "Epoch 40, Loss: 0.0815, Val Loss: 0.0813\n",
            "Epoch 50, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 60, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 70, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 80, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 90, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 100, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 110, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 120, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 130, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 140, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 150, Loss: 0.0815, Val Loss: 0.0812\n",
            "Epoch 160, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 170, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 180, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 190, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 200, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 210, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 220, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 230, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 240, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 250, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 260, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 270, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 280, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 290, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 300, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 310, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 320, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 330, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 340, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 350, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 360, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 370, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 380, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 390, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 400, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 410, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 420, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 430, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 440, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 450, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 460, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 470, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 480, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 490, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 500, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 510, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 520, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 530, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 540, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 550, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 560, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 570, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 580, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 590, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 600, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 610, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 620, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 630, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 640, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 650, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 660, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 670, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 680, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 690, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 700, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 710, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 720, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 730, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 740, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 750, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 760, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 770, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 780, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 790, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 800, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 810, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 820, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 830, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 840, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 850, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 860, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 870, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 880, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 890, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 900, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 910, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 920, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 930, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 940, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 950, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 960, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 970, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 980, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 990, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1000, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1010, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1020, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1030, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1040, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1050, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1060, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1070, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1080, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1090, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1100, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1110, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1120, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1130, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1140, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1150, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1160, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1170, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1180, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1190, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1200, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1210, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1220, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1230, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1240, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1250, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1260, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1270, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1280, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1290, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1300, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1310, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1320, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1330, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1340, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1350, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1360, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1370, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1380, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1390, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1400, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1410, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1420, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1430, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1440, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1450, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1460, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1470, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1480, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1490, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1500, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1510, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1520, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1530, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1540, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1550, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1560, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1570, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1580, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1590, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1600, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1610, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1620, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1630, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1640, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1650, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1660, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1670, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1680, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1690, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1700, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1710, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1720, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1730, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1740, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1750, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1760, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1770, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1780, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1790, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1800, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1810, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1820, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1830, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1840, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1850, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1860, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1870, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1880, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1890, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1900, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1910, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1920, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1930, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1940, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1950, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1960, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1970, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1980, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 1990, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2000, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2010, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2020, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2030, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2040, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2050, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2060, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2070, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2080, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2090, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2100, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2110, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2120, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2130, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2140, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2150, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2160, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2170, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2180, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2190, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2200, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2210, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2220, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2230, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2240, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2250, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2260, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2270, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2280, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2290, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2300, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2310, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2320, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2330, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2340, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2350, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2360, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2370, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2380, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2390, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2400, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2410, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2420, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2430, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2440, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2450, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2460, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2470, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2480, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2490, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2500, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2510, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2520, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2530, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2540, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2550, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2560, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2570, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2580, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2590, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2600, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2610, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2620, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2630, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2640, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2650, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2660, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2670, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2680, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2690, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2700, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2710, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2720, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2730, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2740, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2750, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2760, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2770, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2780, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2790, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2800, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2810, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2820, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2830, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2840, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2850, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2860, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2870, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2880, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2890, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2900, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2910, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2920, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2930, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2940, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2950, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2960, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2970, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2980, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 2990, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3000, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3010, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3020, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3030, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3040, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3050, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3060, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3070, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3080, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3090, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3100, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3110, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3120, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3130, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3140, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3150, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3160, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3170, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3180, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3190, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3200, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3210, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3220, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3230, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3240, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3250, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3260, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3270, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3280, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3290, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3300, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3310, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3320, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3330, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3340, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3350, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3360, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3370, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3380, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3390, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3400, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3410, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3420, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3430, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3440, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3450, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3460, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3470, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3480, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3490, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3500, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3510, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3520, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3530, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3540, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3550, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3560, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3570, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3580, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3590, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3600, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3610, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3620, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3630, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3640, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3650, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3660, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3670, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3680, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3690, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3700, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3710, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3720, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3730, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3740, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3750, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3760, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3770, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3780, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3790, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3800, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3810, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3820, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3830, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3840, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3850, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3860, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3870, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3880, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3890, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3900, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3910, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3920, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3930, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3940, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3950, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3960, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3970, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3980, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 3990, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4000, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4010, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4020, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4030, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4040, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4050, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4060, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4070, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4080, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4090, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4100, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4110, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4120, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4130, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4140, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4150, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4160, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4170, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4180, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4190, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4200, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4210, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4220, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4230, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4240, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4250, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4260, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4270, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4280, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4290, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4300, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4310, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4320, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4330, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4340, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4350, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4360, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4370, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4380, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4390, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4400, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4410, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4420, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4430, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4440, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4450, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4460, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4470, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4480, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4490, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4500, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4510, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4520, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4530, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4540, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4550, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4560, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4570, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4580, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4590, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4600, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4610, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4620, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4630, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4640, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4650, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4660, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4670, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4680, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4690, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4700, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4710, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4720, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4730, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4740, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4750, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4760, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4770, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4780, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4790, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4800, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4810, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4820, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4830, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4840, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4850, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4860, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4870, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4880, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4890, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4900, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4910, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4920, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4930, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4940, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4950, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4960, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4970, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4980, Loss: 0.0814, Val Loss: 0.0812\n",
            "Epoch 4990, Loss: 0.0814, Val Loss: 0.0812\n",
            "Mean Squared Error: 0.0811599932212444\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "バイアス項で切片を示し、任意の位置に調整できるようにオフセットしたことで、より損失の少ない推定が行えていたことが分かる。\n",
        "また、バイアス項の有無に関わらず最初の数百回の反復で損失にほとんど変化がない。テキストのプロット例と比較してこのプログラムの予測精度が低く、まだ改善の余地があると考えられる。"
      ],
      "metadata": {
        "id": "PUGBk4msXGJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題9】特徴量の多次元化"
      ],
      "metadata": {
        "id": "LvWga_hUi8GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量の二乗を入力に利用して、同様に推定を行う。バイアス項は入れる。\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ScratchLinearRegression():\n",
        "    def __init__(self, num_iter=5000, lr=0.01, no_bias=False, verbose=False):\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.no_bias = no_bias\n",
        "        self.verbose = verbose\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "        self.coef_ = None\n",
        "\n",
        "    def _linear_hypothesis(self, X):\n",
        "        return np.dot(X, self.coef_)\n",
        "\n",
        "    def _gradient_descent(self, X, error):\n",
        "        gradient = np.dot(X.T, error) / X.shape[0]\n",
        "        self.coef_ -= self.lr * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.no_bias and X.shape[1] == self.coef_.shape[0] - 1:\n",
        "           X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        return self._linear_hypothesis(X)\n",
        "\n",
        "    def MSE(self, y_pred, y):\n",
        "        return np.mean((y_pred - y) ** 2)\n",
        "\n",
        "    def lossfunction(self, y_pred, y):\n",
        "        return self.MSE(y_pred, y)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        num_features = X.shape[1] + (not self.no_bias)\n",
        "        self.coef_ = np.random.randn(num_features) * 0.01  # Random init\n",
        "\n",
        "        if not self.no_bias:\n",
        "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "            if X_val is not None:\n",
        "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
        "\n",
        "        for i in range(self.iter):\n",
        "            pred = self.predict(X)\n",
        "            error = pred - y\n",
        "            self._gradient_descent(X, error)\n",
        "            self.loss[i] = self.lossfunction(pred, y)\n",
        "            if X_val is not None and y_val is not None:\n",
        "                pred_val = self.predict(X_val)\n",
        "                self.val_loss[i] = self.lossfunction(pred_val, y_val)\n",
        "\n",
        "            if self.verbose and i % 10 == 0:\n",
        "                print(f\"Epoch {i}, Loss: {self.loss[i]:.4f}, Val Loss: {self.val_loss[i]:.4f}\")\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/application_train.csv')\n",
        "\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT']\n",
        "target = 'TARGET'\n",
        "\n",
        "df = df[features + [target]].dropna()\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "# 特徴量の二乗を追加\n",
        "X_squared = X**2\n",
        "X = np.concatenate([X, X_squared], axis=1)\n",
        "\n",
        "\n",
        "# データ分割と標準化\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# モデル作成と学習\n",
        "model = ScratchLinearRegression(num_iter=5000, lr=0.01, no_bias=False, verbose=True)\n",
        "model.fit(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# 推定と評価\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.MSE(y_pred, y_test)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plt.plot(model.loss, label='train')\n",
        "plt.plot(model.val_loss, label='val')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AQI9GjqXgWvU",
        "outputId": "d32c0bd5-376b-4dd5-da4b-1813e622e0bd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0818, Val Loss: 0.0794\n",
            "Epoch 10, Loss: 0.0804, Val Loss: 0.0780\n",
            "Epoch 20, Loss: 0.0792, Val Loss: 0.0769\n",
            "Epoch 30, Loss: 0.0783, Val Loss: 0.0761\n",
            "Epoch 40, Loss: 0.0776, Val Loss: 0.0754\n",
            "Epoch 50, Loss: 0.0770, Val Loss: 0.0748\n",
            "Epoch 60, Loss: 0.0765, Val Loss: 0.0744\n",
            "Epoch 70, Loss: 0.0761, Val Loss: 0.0740\n",
            "Epoch 80, Loss: 0.0758, Val Loss: 0.0738\n",
            "Epoch 90, Loss: 0.0756, Val Loss: 0.0735\n",
            "Epoch 100, Loss: 0.0754, Val Loss: 0.0734\n",
            "Epoch 110, Loss: 0.0752, Val Loss: 0.0732\n",
            "Epoch 120, Loss: 0.0751, Val Loss: 0.0731\n",
            "Epoch 130, Loss: 0.0750, Val Loss: 0.0730\n",
            "Epoch 140, Loss: 0.0749, Val Loss: 0.0729\n",
            "Epoch 150, Loss: 0.0748, Val Loss: 0.0728\n",
            "Epoch 160, Loss: 0.0747, Val Loss: 0.0728\n",
            "Epoch 170, Loss: 0.0747, Val Loss: 0.0728\n",
            "Epoch 180, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 190, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 200, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 210, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Mean Squared Error: 0.07260779475097578\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量の三乗を入力に利用して、同様に推定を行う。バイアス項は入れる。\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ScratchLinearRegression():\n",
        "    def __init__(self, num_iter=5000, lr=0.01, no_bias=False, verbose=False):\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.no_bias = no_bias\n",
        "        self.verbose = verbose\n",
        "        self.loss = np.zeros(self.iter)\n",
        "        self.val_loss = np.zeros(self.iter)\n",
        "        self.coef_ = None\n",
        "\n",
        "    def _linear_hypothesis(self, X):\n",
        "        return np.dot(X, self.coef_)\n",
        "\n",
        "    def _gradient_descent(self, X, error):\n",
        "        gradient = np.dot(X.T, error) / X.shape[0]\n",
        "        self.coef_ -= self.lr * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not self.no_bias and X.shape[1] == self.coef_.shape[0] - 1:\n",
        "           X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        return self._linear_hypothesis(X)\n",
        "\n",
        "    def MSE(self, y_pred, y):\n",
        "        return np.mean((y_pred - y) ** 2)\n",
        "\n",
        "    def lossfunction(self, y_pred, y):\n",
        "        return self.MSE(y_pred, y)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        num_features = X.shape[1] + (not self.no_bias)\n",
        "        self.coef_ = np.random.randn(num_features) * 0.01  # Random init\n",
        "\n",
        "        if not self.no_bias:\n",
        "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "            if X_val is not None:\n",
        "                X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
        "\n",
        "        for i in range(self.iter):\n",
        "            pred = self.predict(X)\n",
        "            error = pred - y\n",
        "            self._gradient_descent(X, error)\n",
        "            self.loss[i] = self.lossfunction(pred, y)\n",
        "            if X_val is not None and y_val is not None:\n",
        "                pred_val = self.predict(X_val)\n",
        "                self.val_loss[i] = self.lossfunction(pred_val, y_val)\n",
        "\n",
        "            if self.verbose and i % 10 == 0:\n",
        "                print(f\"Epoch {i}, Loss: {self.loss[i]:.4f}, Val Loss: {self.val_loss[i]:.4f}\")\n",
        "\n",
        "# データの読み込み\n",
        "df = pd.read_csv('/application_train.csv')\n",
        "\n",
        "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT']\n",
        "target = 'TARGET'\n",
        "\n",
        "df = df[features + [target]].dropna()\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "\n",
        "# 特徴量の三乗を追加\n",
        "X_cube = X**3\n",
        "X = np.concatenate([X, X_cube], axis=1)\n",
        "\n",
        "\n",
        "# データ分割と標準化\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# モデル作成と学習\n",
        "model = ScratchLinearRegression(num_iter=5000, lr=0.01, no_bias=False, verbose=True)\n",
        "model.fit(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# 推定と評価\n",
        "y_pred = model.predict(X_test)\n",
        "mse = model.MSE(y_pred, y_test)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# 学習曲線のプロット\n",
        "plt.plot(model.loss, label='train')\n",
        "plt.plot(model.val_loss, label='val')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db03d96a-a917-4470-ada0-e028e48ce13d",
        "id": "JNXhXL6yhMd5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0814, Val Loss: 0.0789\n",
            "Epoch 10, Loss: 0.0801, Val Loss: 0.0778\n",
            "Epoch 20, Loss: 0.0791, Val Loss: 0.0768\n",
            "Epoch 30, Loss: 0.0782, Val Loss: 0.0760\n",
            "Epoch 40, Loss: 0.0775, Val Loss: 0.0754\n",
            "Epoch 50, Loss: 0.0770, Val Loss: 0.0749\n",
            "Epoch 60, Loss: 0.0765, Val Loss: 0.0744\n",
            "Epoch 70, Loss: 0.0762, Val Loss: 0.0741\n",
            "Epoch 80, Loss: 0.0759, Val Loss: 0.0738\n",
            "Epoch 90, Loss: 0.0756, Val Loss: 0.0736\n",
            "Epoch 100, Loss: 0.0754, Val Loss: 0.0734\n",
            "Epoch 110, Loss: 0.0752, Val Loss: 0.0733\n",
            "Epoch 120, Loss: 0.0751, Val Loss: 0.0731\n",
            "Epoch 130, Loss: 0.0750, Val Loss: 0.0730\n",
            "Epoch 140, Loss: 0.0749, Val Loss: 0.0730\n",
            "Epoch 150, Loss: 0.0748, Val Loss: 0.0729\n",
            "Epoch 160, Loss: 0.0748, Val Loss: 0.0728\n",
            "Epoch 170, Loss: 0.0747, Val Loss: 0.0728\n",
            "Epoch 180, Loss: 0.0747, Val Loss: 0.0728\n",
            "Epoch 190, Loss: 0.0747, Val Loss: 0.0727\n",
            "Epoch 200, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 210, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 220, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 230, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 240, Loss: 0.0746, Val Loss: 0.0727\n",
            "Epoch 250, Loss: 0.0745, Val Loss: 0.0727\n",
            "Epoch 260, Loss: 0.0745, Val Loss: 0.0727\n",
            "Epoch 270, Loss: 0.0745, Val Loss: 0.0727\n",
            "Epoch 280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 1990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 2990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 3990, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4000, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4010, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4020, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4030, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4040, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4050, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4060, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4070, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4080, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4090, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4100, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4110, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4120, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4130, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4140, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4150, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4160, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4170, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4180, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4190, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4200, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4210, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4220, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4230, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4240, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4250, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4260, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4270, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4280, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4290, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4300, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4310, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4320, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4330, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4340, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4350, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4360, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4370, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4380, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4390, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4400, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4410, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4420, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4430, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4440, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4450, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4460, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4470, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4480, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4490, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4500, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4510, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4520, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4530, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4540, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4550, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4560, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4570, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4580, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4590, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4600, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4610, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4620, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4630, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4640, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4650, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4660, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4670, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4680, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4690, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4700, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4710, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4720, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4730, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4740, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4750, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4760, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4770, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4780, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4790, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4800, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4810, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4820, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4830, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4840, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4850, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4860, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4870, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4880, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4890, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4900, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4910, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4920, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4930, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4940, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4950, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4960, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4970, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4980, Loss: 0.0745, Val Loss: 0.0726\n",
            "Epoch 4990, Loss: 0.0745, Val Loss: 0.0726\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'builtin_function_or_method' object has no attribute 'head'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-0e44adb3bc80>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean Squared Error: {mse}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# 学習曲線のプロット\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'head'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "特徴量の二乗や三乗を入力に利用すると推定の精度が上がった。\n",
        "今回のコードでは、二乗と三乗だと三乗の方が反復序盤の精度が高かったが、収束する値の程度には計算した限り差がなかった。"
      ],
      "metadata": {
        "id": "IKugGTSEg_9k"
      }
    }
  ]
}