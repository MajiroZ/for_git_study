{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp+EfKCPP09HpBevrdx0t+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajiroZ/for_git_study/blob/master/TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題1】スクラッチを振り返る\n",
        "\n",
        "\n",
        "1. **重みの初期化**\n",
        "* ランダムな初期値の設定（ゼロでない値）\n",
        "* 初期化手法（Xavier/Glorot初期化、He初期化など）\n",
        "* 適切な範囲での重みの設定\n",
        "\n",
        "2. **エポックのループ処理**\n",
        "* 訓練データ全体を複数回走査するループ\n",
        "* 各エポックでの順伝播と逆伝播\n",
        "* エポックごとの損失値と精度の記録\n",
        "\n",
        "3. 順伝播の実装\n",
        "* 入力データの各層への伝播\n",
        "* 活性化関数の適用\n",
        "* 出力層までの計算\n",
        "\n",
        "4. 逆伝播の実装\n",
        "* 勾配計算\n",
        "* 損失関数に基づく勾配降下\n",
        "* パラメータ（重み、バイアス）の更新\n",
        "\n",
        "5. バッチ処理\n",
        "* データセットの分割\n",
        "* ミニバッチ学習の実装\n",
        "* バッチサイズの決定\n",
        "\n",
        "6. モデルの評価\n",
        "* 検証データでの性能測定\n",
        "* 過学習の検出\n",
        "* (学習曲線のプロット)"
      ],
      "metadata": {
        "id": "Q_qyzktMCTLt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dSSRa1AF_loc",
        "outputId": "17fffe98-f4a3-45e2-bcba-6fefbae25739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
              "50    51            7.0           3.2            4.7           1.4   \n",
              "51    52            6.4           3.2            4.5           1.5   \n",
              "52    53            6.9           3.1            4.9           1.5   \n",
              "53    54            5.5           2.3            4.0           1.3   \n",
              "54    55            6.5           2.8            4.6           1.5   \n",
              "..   ...            ...           ...            ...           ...   \n",
              "145  146            6.7           3.0            5.2           2.3   \n",
              "146  147            6.3           2.5            5.0           1.9   \n",
              "147  148            6.5           3.0            5.2           2.0   \n",
              "148  149            6.2           3.4            5.4           2.3   \n",
              "149  150            5.9           3.0            5.1           1.8   \n",
              "\n",
              "             Species  \n",
              "50   Iris-versicolor  \n",
              "51   Iris-versicolor  \n",
              "52   Iris-versicolor  \n",
              "53   Iris-versicolor  \n",
              "54   Iris-versicolor  \n",
              "..               ...  \n",
              "145   Iris-virginica  \n",
              "146   Iris-virginica  \n",
              "147   Iris-virginica  \n",
              "148   Iris-virginica  \n",
              "149   Iris-virginica  \n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53e7c279-459f-4373-bccf-a0a825484f72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>51</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>52</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>54</td>\n",
              "      <td>5.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>55</td>\n",
              "      <td>6.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53e7c279-459f-4373-bccf-a0a825484f72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53e7c279-459f-4373-bccf-a0a825484f72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53e7c279-459f-4373-bccf-a0a825484f72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a67f5e3f-a666-4fa2-a2db-e16cf6c52b73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a67f5e3f-a666-4fa2-a2db-e16cf6c52b73')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a67f5e3f-a666-4fa2-a2db-e16cf6c52b73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_beba1608-c95c-420f-afd2-fdd0ffcd2b88\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_filtered')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_beba1608-c95c-420f-afd2-fdd0ffcd2b88 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_filtered');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered",
              "summary": "{\n  \"name\": \"df_filtered\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 51,\n        \"max\": 150,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          134,\n          104,\n          121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SepalLengthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6628344400749671,\n        \"min\": 4.9,\n        \"max\": 7.9,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          5.2,\n          7.7,\n          6.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SepalWidthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33275100649469463,\n        \"min\": 2.0,\n        \"max\": 3.8,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3.2,\n          3.1,\n          2.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PetalLengthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8255784626428904,\n        \"min\": 3.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          3.8,\n          6.0,\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PetalWidthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42476850498628405,\n        \"min\": 1.0,\n        \"max\": 2.5,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1.4,\n          1.5,\n          1.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Iris-virginica\",\n          \"Iris-versicolor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Irisデータセット\n",
        "try:\n",
        "    df = pd.read_csv('/Iris.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Iris.csv' not found. Please make sure the file exists in the current directory.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# 目的変数がIris-versicolorまたはIris-virginicaのデータのみ抽出\n",
        "df_filtered = df[df['Species'].isin(['Iris-versicolor', 'Iris-virginica'])]\n",
        "\n",
        "# 結果の表示\n",
        "df_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題2】スクラッチとTensorFlowの対応を考える\n",
        "\n",
        "1. 重みの初期化\n",
        "```python\n",
        "weights = {\n",
        "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
        "    'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
        "    'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]])\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
        "    'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
        "    'b3': tf.Variable(tf.random_normal([n_classes]))\n",
        "}\n",
        "```\n",
        "- `tf.random_normal()`を使用してランダムな正規分布に基づく重みを初期化\n",
        "- `tf.Variable()`で変数として定義し、学習可能なパラメータとしている\n",
        "\n",
        "2. エポックのループ処理\n",
        "```python\n",
        "for epoch in range(num_epochs):\n",
        "    total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
        "    total_loss = 0\n",
        "    for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "        # ミニバッチごとにループ\n",
        "        sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "        total_loss += loss\n",
        "```\n",
        "- `num_epochs`で指定した回数分、学習データ全体を走査\n",
        "- ミニバッチイテレータを使用してデータを分割\n",
        "- 各エポックで損失を計算し、累積\n",
        "\n",
        "3. 順伝播の実装\n",
        "```python\n",
        "def example_net(x):\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "```\n",
        "- 各層での行列乗算(`tf.matmul()`)\n",
        "- 活性化関数の適用（この場合はReLU）\n",
        "- 最終層の出力計算\n",
        "\n",
        "4. 逆伝播と最適化\n",
        "```python\n",
        "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "```\n",
        "- 損失関数（シグモイド交差エントロピー）の定義\n",
        "- Adamオプティマイザを使用\n",
        "- `minimize()`メソッドで自動的に逆伝播と重み更新を実行\n",
        "\n",
        "5. モデルの評価\n",
        "```python\n",
        "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "```\n",
        "- 予測と正解ラベルの比較\n",
        "- 精度（accuracy）の計算\n",
        "\n",
        "これらの実装で、TensorFlow（この例では1.x系）でディープラーニングモデルの基本的な学習プロセスを実現してる。"
      ],
      "metadata": {
        "id": "cW9L9HknJDAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題3】3種類すべての目的変数を使用したIrisのモデルを作成"
      ],
      "metadata": {
        "id": "9mluHXk1ciin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Irisの3種類の目的変数をすべて使ってTensorFlowで学習・推定するニューラルネットワーク\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "# データセットの読み込み\n",
        "try:\n",
        "    df = pd.read_csv('/Iris.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'Iris.csv' not found. Please make sure the file exists in the current directory.\")\n",
        "    exit()\n",
        "\n",
        "# データの前処理\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "X = np.array(X)\n",
        "\n",
        "# ラベルを数値に変換\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = y.astype(np.int64)[:, np.newaxis]\n",
        "\n",
        "\n",
        "# train, val, testに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "# ミニバッチ処理クラス\n",
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size=10, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self.X = X[shuffle_index]\n",
        "        self.y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self.X[p0:p1], self.y[p0:p1]\n",
        "\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 3 #3種類の目的変数\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.compat.v1.placeholder(\"int64\", [None, 1]) #目的変数の型をint64に修正\n",
        "\n",
        "# ワンホットエンコーディング\n",
        "Y_onehot = tf.one_hot(Y, depth=n_classes)\n",
        "\n",
        "# trainのミニバッチイテレータ\n",
        "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
        "\n",
        "# ネットワーク構造の定義\n",
        "def example_net(x):\n",
        "    tf.compat.v1.random.set_random_seed(0)\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.compat.v1.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.compat.v1.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.compat.v1.random_normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.compat.v1.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.compat.v1.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.compat.v1.random_normal([n_classes]))\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X)\n",
        "\n",
        "# 目的関数、最適化手法、評価指標\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_onehot, logits=logits))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(tf.reshape(Y_onehot, [-1, n_classes]), 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# variableの初期化\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.compat.v1.Session() as sess: # Use tf.compat.v1.Session\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
        "        total_loss = 0\n",
        "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
        "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
        "            total_loss += loss\n",
        "        total_loss /= n_samples\n",
        "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n",
        "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_acc : {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5fURT0KPaKn",
        "outputId": "7668504d-f083-4844-d29c-dc90775e1fb8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 18.2232, val_loss : 143.0447, acc : 0.292\n",
            "Epoch 1, loss : 10.1237, val_loss : 72.9604, acc : 0.083\n",
            "Epoch 2, loss : 4.5031, val_loss : 16.4131, acc : 0.458\n",
            "Epoch 3, loss : 1.6937, val_loss : 9.7921, acc : 0.375\n",
            "Epoch 4, loss : 0.6223, val_loss : 1.7191, acc : 0.625\n",
            "Epoch 5, loss : 0.3016, val_loss : 0.5223, acc : 0.792\n",
            "Epoch 6, loss : 0.1826, val_loss : 0.3126, acc : 0.875\n",
            "Epoch 7, loss : 0.1707, val_loss : 0.3292, acc : 0.833\n",
            "Epoch 8, loss : 0.1429, val_loss : 0.2239, acc : 0.958\n",
            "Epoch 9, loss : 0.1321, val_loss : 0.2094, acc : 0.958\n",
            "Epoch 10, loss : 0.1178, val_loss : 0.2746, acc : 0.958\n",
            "Epoch 11, loss : 0.1078, val_loss : 0.2637, acc : 0.958\n",
            "Epoch 12, loss : 0.0990, val_loss : 0.3189, acc : 0.958\n",
            "Epoch 13, loss : 0.0892, val_loss : 0.3346, acc : 0.958\n",
            "Epoch 14, loss : 0.0796, val_loss : 0.3555, acc : 0.958\n",
            "Epoch 15, loss : 0.0710, val_loss : 0.3679, acc : 0.958\n",
            "Epoch 16, loss : 0.0646, val_loss : 0.3736, acc : 0.958\n",
            "Epoch 17, loss : 0.0591, val_loss : 0.3779, acc : 0.958\n",
            "Epoch 18, loss : 0.0542, val_loss : 0.3822, acc : 0.958\n",
            "Epoch 19, loss : 0.0499, val_loss : 0.3917, acc : 0.958\n",
            "Epoch 20, loss : 0.0469, val_loss : 0.3925, acc : 0.958\n",
            "Epoch 21, loss : 0.0446, val_loss : 0.3987, acc : 0.958\n",
            "Epoch 22, loss : 0.0432, val_loss : 0.3985, acc : 0.958\n",
            "Epoch 23, loss : 0.0418, val_loss : 0.4034, acc : 0.958\n",
            "Epoch 24, loss : 0.0407, val_loss : 0.4054, acc : 0.958\n",
            "Epoch 25, loss : 0.0396, val_loss : 0.4099, acc : 0.958\n",
            "Epoch 26, loss : 0.0385, val_loss : 0.4143, acc : 0.958\n",
            "Epoch 27, loss : 0.0375, val_loss : 0.4197, acc : 0.958\n",
            "Epoch 28, loss : 0.0366, val_loss : 0.4261, acc : 0.958\n",
            "Epoch 29, loss : 0.0357, val_loss : 0.4328, acc : 0.958\n",
            "Epoch 30, loss : 0.0349, val_loss : 0.4405, acc : 0.958\n",
            "Epoch 31, loss : 0.0341, val_loss : 0.4482, acc : 0.958\n",
            "Epoch 32, loss : 0.0334, val_loss : 0.4565, acc : 0.958\n",
            "Epoch 33, loss : 0.0328, val_loss : 0.4647, acc : 0.958\n",
            "Epoch 34, loss : 0.0322, val_loss : 0.4733, acc : 0.958\n",
            "Epoch 35, loss : 0.0316, val_loss : 0.4818, acc : 0.958\n",
            "Epoch 36, loss : 0.0311, val_loss : 0.4906, acc : 0.958\n",
            "Epoch 37, loss : 0.0306, val_loss : 0.4994, acc : 0.958\n",
            "Epoch 38, loss : 0.0301, val_loss : 0.5084, acc : 0.958\n",
            "Epoch 39, loss : 0.0296, val_loss : 0.5176, acc : 0.958\n",
            "Epoch 40, loss : 0.0291, val_loss : 0.5270, acc : 0.917\n",
            "Epoch 41, loss : 0.0287, val_loss : 0.5362, acc : 0.917\n",
            "Epoch 42, loss : 0.0282, val_loss : 0.5455, acc : 0.917\n",
            "Epoch 43, loss : 0.0278, val_loss : 0.5552, acc : 0.917\n",
            "Epoch 44, loss : 0.0273, val_loss : 0.5649, acc : 0.917\n",
            "Epoch 45, loss : 0.0269, val_loss : 0.5748, acc : 0.917\n",
            "Epoch 46, loss : 0.0265, val_loss : 0.5848, acc : 0.917\n",
            "Epoch 47, loss : 0.0261, val_loss : 0.5947, acc : 0.917\n",
            "Epoch 48, loss : 0.0256, val_loss : 0.6047, acc : 0.917\n",
            "Epoch 49, loss : 0.0252, val_loss : 0.6145, acc : 0.917\n",
            "Epoch 50, loss : 0.0248, val_loss : 0.6243, acc : 0.917\n",
            "Epoch 51, loss : 0.0244, val_loss : 0.6340, acc : 0.917\n",
            "Epoch 52, loss : 0.0240, val_loss : 0.6435, acc : 0.917\n",
            "Epoch 53, loss : 0.0236, val_loss : 0.6528, acc : 0.917\n",
            "Epoch 54, loss : 0.0232, val_loss : 0.6619, acc : 0.917\n",
            "Epoch 55, loss : 0.0228, val_loss : 0.6709, acc : 0.917\n",
            "Epoch 56, loss : 0.0224, val_loss : 0.6796, acc : 0.917\n",
            "Epoch 57, loss : 0.0220, val_loss : 0.6881, acc : 0.917\n",
            "Epoch 58, loss : 0.0216, val_loss : 0.6965, acc : 0.917\n",
            "Epoch 59, loss : 0.0212, val_loss : 0.7045, acc : 0.917\n",
            "Epoch 60, loss : 0.0208, val_loss : 0.7124, acc : 0.917\n",
            "Epoch 61, loss : 0.0204, val_loss : 0.7200, acc : 0.917\n",
            "Epoch 62, loss : 0.0200, val_loss : 0.7274, acc : 0.917\n",
            "Epoch 63, loss : 0.0196, val_loss : 0.7399, acc : 0.917\n",
            "Epoch 64, loss : 0.0192, val_loss : 0.7510, acc : 0.917\n",
            "Epoch 65, loss : 0.0188, val_loss : 0.7597, acc : 0.917\n",
            "Epoch 66, loss : 0.0184, val_loss : 0.7659, acc : 0.917\n",
            "Epoch 67, loss : 0.0180, val_loss : 0.7725, acc : 0.917\n",
            "Epoch 68, loss : 0.0177, val_loss : 0.7775, acc : 0.917\n",
            "Epoch 69, loss : 0.0173, val_loss : 0.7834, acc : 0.917\n",
            "Epoch 70, loss : 0.0169, val_loss : 0.7876, acc : 0.917\n",
            "Epoch 71, loss : 0.0165, val_loss : 0.7930, acc : 0.917\n",
            "Epoch 72, loss : 0.0161, val_loss : 0.7964, acc : 0.917\n",
            "Epoch 73, loss : 0.0157, val_loss : 0.8016, acc : 0.917\n",
            "Epoch 74, loss : 0.0153, val_loss : 0.8039, acc : 0.917\n",
            "Epoch 75, loss : 0.0149, val_loss : 0.8091, acc : 0.917\n",
            "Epoch 76, loss : 0.0146, val_loss : 0.8098, acc : 0.917\n",
            "Epoch 77, loss : 0.0141, val_loss : 0.8158, acc : 0.917\n",
            "Epoch 78, loss : 0.0138, val_loss : 0.8184, acc : 0.917\n",
            "Epoch 79, loss : 0.0134, val_loss : 0.8280, acc : 0.917\n",
            "Epoch 80, loss : 0.0130, val_loss : 0.8267, acc : 0.917\n",
            "Epoch 81, loss : 0.0126, val_loss : 0.8338, acc : 0.917\n",
            "Epoch 82, loss : 0.0123, val_loss : 0.8275, acc : 0.917\n",
            "Epoch 83, loss : 0.0119, val_loss : 0.8379, acc : 0.917\n",
            "Epoch 84, loss : 0.0116, val_loss : 0.8243, acc : 0.917\n",
            "Epoch 85, loss : 0.0112, val_loss : 0.8474, acc : 0.917\n",
            "Epoch 86, loss : 0.0110, val_loss : 0.8188, acc : 0.917\n",
            "Epoch 87, loss : 0.0105, val_loss : 0.8611, acc : 0.917\n",
            "Epoch 88, loss : 0.0104, val_loss : 0.7972, acc : 0.917\n",
            "Epoch 89, loss : 0.0098, val_loss : 0.8823, acc : 0.917\n",
            "Epoch 90, loss : 0.0100, val_loss : 0.7299, acc : 0.917\n",
            "Epoch 91, loss : 0.0091, val_loss : 0.9531, acc : 0.917\n",
            "Epoch 92, loss : 0.0107, val_loss : 0.5325, acc : 0.917\n",
            "Epoch 93, loss : 0.0078, val_loss : 1.0745, acc : 0.917\n",
            "Epoch 94, loss : 0.0115, val_loss : 0.4525, acc : 0.917\n",
            "Epoch 95, loss : 0.0072, val_loss : 1.0314, acc : 0.917\n",
            "Epoch 96, loss : 0.0100, val_loss : 0.6735, acc : 0.917\n",
            "Epoch 97, loss : 0.0076, val_loss : 1.0120, acc : 0.917\n",
            "Epoch 98, loss : 0.0098, val_loss : 0.5132, acc : 0.917\n",
            "Epoch 99, loss : 0.0062, val_loss : 0.9670, acc : 0.917\n",
            "test_acc : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題4】House Pricesのモデルを作成"
      ],
      "metadata": {
        "id": "YpaD1bx9cpiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import MinMaxScaler from sklearn.preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "dataset_path =\"/train.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "y = df[\"SalePrice\"]\n",
        "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
        "y = np.array(y)\n",
        "X = np.array(X)\n",
        "y = y.astype(int)[:, np.newaxis]\n",
        "y = np.log(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "mmsc = MinMaxScaler()\n",
        "X_train = mmsc.fit_transform(X_train)\n",
        "X_test = mmsc.transform(X_test)\n",
        "X_val = mmsc.transform(X_val)"
      ],
      "metadata": {
        "id": "NKgF2BDvdysY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('/train.csv') # train.csvへのパスを指定\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'train.csv' not found. Please make sure the file exists in the current directory.\")\n",
        "    exit()\n",
        "\n",
        "y = df[\"SalePrice\"]\n",
        "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
        "\n",
        "#欠損値を0で補完\n",
        "X = X.fillna(0)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "y = y.astype(int)[:, np.newaxis]\n",
        "y = np.log(y)\n",
        "\n",
        "# train, val, testに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# MinMaxScalerで特徴量をスケーリング\n",
        "mmsc = MinMaxScaler()\n",
        "X_train = mmsc.fit_transform(X_train)\n",
        "X_test = mmsc.transform(X_test)\n",
        "X_val = mmsc.transform(X_val)\n",
        "\n",
        "n_input = X_train.shape[1]\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "num_epochs = 100\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "n_samples = X_train.shape[0]\n",
        "\n",
        "# 計算グラフに渡す引数の形を決める\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.compat.v1.placeholder(\"float\", [None, 1])\n",
        "\n",
        "# ネットワーク構造の定義\n",
        "def example_net(x):\n",
        "    tf.compat.v1.random.set_random_seed(0)\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.compat.v1.random_normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.compat.v1.random_normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.compat.v1.random_normal([n_hidden2, 1])) # 出力層のユニット数を1に\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.compat.v1.random_normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.compat.v1.random_normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.compat.v1.random_normal([1])) # 出力層のバイアスも1に\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "logits = example_net(X)\n",
        "\n",
        "# 目的関数、最適化手法、評価指標\n",
        "loss_op = tf.reduce_mean(tf.square(logits - Y)) # 平均二乗誤差を使用\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# variableの初期化\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "# 計算グラフの実行\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "          sess.run(train_op, feed_dict={X: X_train[i: i+batch_size], Y: y_train[i: i+batch_size]})\n",
        "          loss = sess.run(loss_op, feed_dict={X: X_train[i:i+batch_size], Y:y_train[i:i+batch_size]})\n",
        "          total_loss += loss\n",
        "\n",
        "        total_loss /= (n_samples / batch_size) # バッチサイズで割る\n",
        "        val_loss = sess.run(loss_op, feed_dict={X: X_val, Y: y_val})\n",
        "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}\".format(epoch, total_loss, val_loss))\n",
        "    test_loss = sess.run(loss_op, feed_dict={X: X_test, Y: y_test})\n",
        "    print(\"test_loss : {:.3f}\".format(test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpbhTfl3dX-e",
        "outputId": "4c583f12-ac66-4505-8398-0d5e2aeac719"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss : 749.2937, val_loss : 37.2270\n",
            "Epoch 1, loss : 22.9719, val_loss : 15.2548\n",
            "Epoch 2, loss : 10.0288, val_loss : 6.2337\n",
            "Epoch 3, loss : 4.6160, val_loss : 2.6452\n",
            "Epoch 4, loss : 2.3816, val_loss : 1.2915\n",
            "Epoch 5, loss : 1.4922, val_loss : 0.8048\n",
            "Epoch 6, loss : 1.1083, val_loss : 0.5969\n",
            "Epoch 7, loss : 0.8986, val_loss : 0.4720\n",
            "Epoch 8, loss : 0.7602, val_loss : 0.3870\n",
            "Epoch 9, loss : 0.6608, val_loss : 0.3298\n",
            "Epoch 10, loss : 0.5861, val_loss : 0.2914\n",
            "Epoch 11, loss : 0.5280, val_loss : 0.2639\n",
            "Epoch 12, loss : 0.4809, val_loss : 0.2423\n",
            "Epoch 13, loss : 0.4411, val_loss : 0.2251\n",
            "Epoch 14, loss : 0.4070, val_loss : 0.2110\n",
            "Epoch 15, loss : 0.3773, val_loss : 0.1992\n",
            "Epoch 16, loss : 0.3502, val_loss : 0.1889\n",
            "Epoch 17, loss : 0.3246, val_loss : 0.1790\n",
            "Epoch 18, loss : 0.2997, val_loss : 0.1679\n",
            "Epoch 19, loss : 0.2744, val_loss : 0.1556\n",
            "Epoch 20, loss : 0.2506, val_loss : 0.1428\n",
            "Epoch 21, loss : 0.2267, val_loss : 0.1301\n",
            "Epoch 22, loss : 0.2041, val_loss : 0.1190\n",
            "Epoch 23, loss : 0.1834, val_loss : 0.1096\n",
            "Epoch 24, loss : 0.1652, val_loss : 0.1004\n",
            "Epoch 25, loss : 0.1493, val_loss : 0.0935\n",
            "Epoch 26, loss : 0.1355, val_loss : 0.0888\n",
            "Epoch 27, loss : 0.1242, val_loss : 0.0878\n",
            "Epoch 28, loss : 0.1153, val_loss : 0.0871\n",
            "Epoch 29, loss : 0.1085, val_loss : 0.0875\n",
            "Epoch 30, loss : 0.1028, val_loss : 0.0869\n",
            "Epoch 31, loss : 0.0979, val_loss : 0.0858\n",
            "Epoch 32, loss : 0.0937, val_loss : 0.0848\n",
            "Epoch 33, loss : 0.0902, val_loss : 0.0829\n",
            "Epoch 34, loss : 0.0870, val_loss : 0.0805\n",
            "Epoch 35, loss : 0.0841, val_loss : 0.0784\n",
            "Epoch 36, loss : 0.0817, val_loss : 0.0767\n",
            "Epoch 37, loss : 0.0794, val_loss : 0.0761\n",
            "Epoch 38, loss : 0.0776, val_loss : 0.0760\n",
            "Epoch 39, loss : 0.0760, val_loss : 0.0764\n",
            "Epoch 40, loss : 0.0748, val_loss : 0.0777\n",
            "Epoch 41, loss : 0.0738, val_loss : 0.0786\n",
            "Epoch 42, loss : 0.0727, val_loss : 0.0780\n",
            "Epoch 43, loss : 0.0712, val_loss : 0.0764\n",
            "Epoch 44, loss : 0.0697, val_loss : 0.0741\n",
            "Epoch 45, loss : 0.0683, val_loss : 0.0721\n",
            "Epoch 46, loss : 0.0669, val_loss : 0.0703\n",
            "Epoch 47, loss : 0.0661, val_loss : 0.0685\n",
            "Epoch 48, loss : 0.0654, val_loss : 0.0670\n",
            "Epoch 49, loss : 0.0649, val_loss : 0.0657\n",
            "Epoch 50, loss : 0.0643, val_loss : 0.0646\n",
            "Epoch 51, loss : 0.0642, val_loss : 0.0637\n",
            "Epoch 52, loss : 0.0642, val_loss : 0.0632\n",
            "Epoch 53, loss : 0.0640, val_loss : 0.0627\n",
            "Epoch 54, loss : 0.0640, val_loss : 0.0626\n",
            "Epoch 55, loss : 0.0638, val_loss : 0.0627\n",
            "Epoch 56, loss : 0.0635, val_loss : 0.0630\n",
            "Epoch 57, loss : 0.0631, val_loss : 0.0625\n",
            "Epoch 58, loss : 0.0630, val_loss : 0.0618\n",
            "Epoch 59, loss : 0.0625, val_loss : 0.0604\n",
            "Epoch 60, loss : 0.0626, val_loss : 0.0611\n",
            "Epoch 61, loss : 0.0625, val_loss : 0.0630\n",
            "Epoch 62, loss : 0.0625, val_loss : 0.0667\n",
            "Epoch 63, loss : 0.0625, val_loss : 0.0707\n",
            "Epoch 64, loss : 0.0621, val_loss : 0.0743\n",
            "Epoch 65, loss : 0.0624, val_loss : 0.0778\n",
            "Epoch 66, loss : 0.0639, val_loss : 0.0823\n",
            "Epoch 67, loss : 0.0646, val_loss : 0.0861\n",
            "Epoch 68, loss : 0.0661, val_loss : 0.0906\n",
            "Epoch 69, loss : 0.0685, val_loss : 0.1005\n",
            "Epoch 70, loss : 0.0697, val_loss : 0.1048\n",
            "Epoch 71, loss : 0.0711, val_loss : 0.1062\n",
            "Epoch 72, loss : 0.0724, val_loss : 0.1051\n",
            "Epoch 73, loss : 0.0732, val_loss : 0.1022\n",
            "Epoch 74, loss : 0.0737, val_loss : 0.0993\n",
            "Epoch 75, loss : 0.0756, val_loss : 0.0996\n",
            "Epoch 76, loss : 0.0763, val_loss : 0.0945\n",
            "Epoch 77, loss : 0.0777, val_loss : 0.0905\n",
            "Epoch 78, loss : 0.0772, val_loss : 0.0854\n",
            "Epoch 79, loss : 0.0768, val_loss : 0.0799\n",
            "Epoch 80, loss : 0.0762, val_loss : 0.0732\n",
            "Epoch 81, loss : 0.0773, val_loss : 0.0699\n",
            "Epoch 82, loss : 0.0761, val_loss : 0.0658\n",
            "Epoch 83, loss : 0.0752, val_loss : 0.0604\n",
            "Epoch 84, loss : 0.0747, val_loss : 0.0571\n",
            "Epoch 85, loss : 0.0743, val_loss : 0.0548\n",
            "Epoch 86, loss : 0.0736, val_loss : 0.0530\n",
            "Epoch 87, loss : 0.0726, val_loss : 0.0529\n",
            "Epoch 88, loss : 0.0720, val_loss : 0.0538\n",
            "Epoch 89, loss : 0.0711, val_loss : 0.0563\n",
            "Epoch 90, loss : 0.0703, val_loss : 0.0592\n",
            "Epoch 91, loss : 0.0701, val_loss : 0.0626\n",
            "Epoch 92, loss : 0.0697, val_loss : 0.0660\n",
            "Epoch 93, loss : 0.0695, val_loss : 0.0697\n",
            "Epoch 94, loss : 0.0692, val_loss : 0.0733\n",
            "Epoch 95, loss : 0.0689, val_loss : 0.0752\n",
            "Epoch 96, loss : 0.0687, val_loss : 0.0790\n",
            "Epoch 97, loss : 0.0683, val_loss : 0.0792\n",
            "Epoch 98, loss : 0.0672, val_loss : 0.0798\n",
            "Epoch 99, loss : 0.0676, val_loss : 0.0816\n",
            "test_loss : 0.109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題5】MNISTのモデルを作成"
      ],
      "metadata": {
        "id": "Z8v6oRNPfC-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# Import mnist from tensorflow.keras.datasets\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "y_train = y_train.astype(int)[:, np.newaxis]\n",
        "y_test = y_test.astype(int)[:, np.newaxis]\n",
        "enc = OneHotEncoder(handle_unknown='ignore', categories='auto')\n",
        "y_train_one_hot = enc.fit_transform(y_train[:])\n",
        "y_test_one_hot = enc.fit_transform(y_test[:])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
      ],
      "metadata": {
        "id": "NgeKKekwfg9L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "X_train = X_train.reshape(-1, 784).astype(float) / 255\n",
        "X_test = X_test.reshape(-1, 784).astype(float) / 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_one_hot = enc.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_epochs = 20\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = 784\n",
        "n_classes = 10\n",
        "\n",
        "# Define placeholders for input and output\n",
        "X = tf.compat.v1.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "# Define the neural network\n",
        "def example_net(x):\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.random.normal([n_input, n_hidden1])),\n",
        "        'w2': tf.Variable(tf.random.normal([n_hidden1, n_hidden2])),\n",
        "        'w3': tf.Variable(tf.random.normal([n_hidden2, n_classes]))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.random.normal([n_hidden1])),\n",
        "        'b2': tf.Variable(tf.random.normal([n_hidden2])),\n",
        "        'b3': tf.Variable(tf.random.normal([n_classes]))\n",
        "    }\n",
        "\n",
        "    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['w1']), biases['b1']))\n",
        "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['w2']), biases['b2']))\n",
        "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
        "    return layer_output\n",
        "\n",
        "# Build the model\n",
        "logits = example_net(X)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "# Start training\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = int(X_train.shape[0] / batch_size)\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = X_train[i * batch_size:(i + 1) * batch_size], y_train[i * batch_size:(i + 1) * batch_size]\n",
        "            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
        "            avg_cost += c / total_batch\n",
        "        print(\"Epoch:\", '%04d' % (epoch + 1), \"cost={:.9f}\".format(avg_cost))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Accuracy:\", accuracy.eval({X: X_test, Y: y_test_one_hot}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0XOrJ4VgI_d",
        "outputId": "41fd5faf-90ce-4927-f0bf-138125229178"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost=85.507478857\n",
            "Epoch: 0002 cost=19.628206881\n",
            "Epoch: 0003 cost=12.510167856\n",
            "Epoch: 0004 cost=9.192040552\n",
            "Epoch: 0005 cost=7.132923970\n",
            "Epoch: 0006 cost=5.740982013\n",
            "Epoch: 0007 cost=4.716303780\n",
            "Epoch: 0008 cost=3.956058896\n",
            "Epoch: 0009 cost=3.370950834\n",
            "Epoch: 0010 cost=2.898652833\n",
            "Epoch: 0011 cost=2.512472238\n",
            "Epoch: 0012 cost=2.196542357\n",
            "Epoch: 0013 cost=1.936289814\n",
            "Epoch: 0014 cost=1.711242853\n",
            "Epoch: 0015 cost=1.518095934\n",
            "Epoch: 0016 cost=1.349413691\n",
            "Epoch: 0017 cost=1.203014165\n",
            "Epoch: 0018 cost=1.082966051\n",
            "Epoch: 0019 cost=0.976389866\n",
            "Epoch: 0020 cost=0.876413763\n",
            "Optimization Finished!\n",
            "Accuracy: 0.8992\n"
          ]
        }
      ]
    }
  ]
}