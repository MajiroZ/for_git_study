{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCpxk7seKTkTMdM2mwo135",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajiroZ/for_git_study/blob/master/CNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_Zr5odkQluR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "7fc7ad98-b5f1-4bed-829a-d2552c5a558a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([64, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils\n",
        "\n",
        "# MNISTデータセットのダウンロードと変換\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # 画像データをTensorに変換\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # 平均と標準偏差で正規化\n",
        "])\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoaderの作成\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=64, shuffle=False)\n",
        "\n",
        "# データの形状確認 (NCHW形式)\n",
        "for images, labels in train_loader:\n",
        "    print(\"Image shape:\", images.shape) # 例: torch.Size([64, 1, 28, 28])\n",
        "    break\n",
        "\n",
        "# データセットのサンプル表示\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画像を可視化する関数\n",
        "def show_image(img):\n",
        "    img = img / 2 + 0.5     # 正規化を元に戻す\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# データセットからサンプル画像を取得\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 最初の画像を表示\n",
        "import numpy as np\n",
        "show_image(utils.make_grid(images[0]))\n",
        "labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データとテストデータの作成\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_pred = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    X_train.append(images)\n",
        "    y_train.append(labels)\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    X_pred.append(images)\n",
        "    y_pred.append(labels)\n",
        "\n",
        "# リストをTensorに変換\n",
        "X_train = torch.cat(X_train, dim=0)\n",
        "y_train = torch.cat(y_train, dim=0)\n",
        "X_pred = torch.cat(X_pred, dim=0)\n",
        "y_pred = torch.cat(y_pred, dim=0)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_pred shape:\", X_pred.shape)\n",
        "print(\"y_pred shape:\", y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqCQKrhLgt-p",
        "outputId": "b4d5eae4-b78f-4061-e8c4-e6eb6dea5335"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([60000, 1, 28, 28])\n",
            "y_train shape: torch.Size([60000])\n",
            "X_pred shape: torch.Size([10000, 1, 28, 28])\n",
            "y_pred shape: torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題1】2次元畳み込み層の作成"
      ],
      "metadata": {
        "id": "95T_JHexlzDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConv2d():\n",
        "    def __init__(self, F, C, FH, FW, P, S, initializer=None, optimizer=None, activation=None):\n",
        "        self.P = P\n",
        "        self.S = S\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        self.W = self.initializer.W(F, C, FH, FW)\n",
        "        self.B = self.initializer.B(F)\n",
        "\n",
        "    def output_shape2d(self, H, W, PH, PW, FH, FW, SH, SW):\n",
        "        OH = (H + 2 * PH - FH) / SH + 1\n",
        "        OW = (W + 2 * PW - FW) / SW + 1\n",
        "        return int(OH), int(OW)\n",
        "\n",
        "    def forward(self, X,debug=False):\n",
        "        self.X = X\n",
        "        N,C,H,W = self.X.shape\n",
        "        F,C,FH,FW = self.W.shape\n",
        "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "        A = np.zeros([N,F,OH,OW])\n",
        "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        A[n,ch,row,col] = np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
        "        if debug == True:\n",
        "            return A\n",
        "        else:\n",
        "            return self.activation.forward(A)\n",
        "\n",
        "    def backward(self, dZ,debug=False):\n",
        "        if debug==True:\n",
        "            dA = dZ\n",
        "        else:\n",
        "            dA = self.activation.backward(dZ)\n",
        "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "        dZ = np.zeros(self.X_pad.shape)\n",
        "        self.dW = np.zeros(self.W.shape)\n",
        "        self.dB = np.zeros(self.B.shape)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "        if self.P == 0:\n",
        "            dZ = np.delete(dZ,[0,H-1],axis=2)\n",
        "            dZ = np.delete(dZ,[0,W-1],axis=3)\n",
        "        else:\n",
        "            dl_rows = range(self.P),range(H+self.P,H+2*self.P)\n",
        "            dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "            dl_cols = range(self.P),range(W+self.P,W+2*self.P)\n",
        "            dZ = np.delete(dZ,dl_cols,axis=3)"
      ],
      "metadata": {
        "id": "294DAwrwu-m1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.clip(A, 0, None)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.clip(A, 0, None)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
        "\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return"
      ],
      "metadata": {
        "id": "0nB7mXg3owy5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializerConv2d():\n",
        "    def __init__(self,sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "    def W(self,F,C,FH,FW):\n",
        "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
        "    def B(self,F):\n",
        "        return np.zeros(F)\n",
        "\n",
        "    def output_shaped2d(self, H, W, PH, PW, FH, FW, SH, SW):\n",
        "        OH = (H + 2 * PH - FH) / SH + 1\n",
        "        OW = (W + 2 * PW - FW) / SW + 1\n",
        "        return int(OH), int(OW)\n",
        "\n",
        "    def forward(self, X,debug=False):\n",
        "        self.X = X\n",
        "        N,C,H,W = self.X.shape\n",
        "        F,C,FH,FW = self.W.shape\n",
        "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "        A = np.zeros([N,F,OH,OW])\n",
        "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        A[n,ch,row,col] = np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
        "        if debug==True:\n",
        "            return A\n",
        "        else:\n",
        "            return  self.activation.forward(A)\n",
        "\n",
        "    def backward(self, dZ,debug=False):\n",
        "        if debug==True:\n",
        "            dA = dZ\n",
        "        else:\n",
        "            dA = self.activation.backward(dZ)\n",
        "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "        dZ = np.zeros(self.X_pad.shape)\n",
        "        self.dW = np.zeros(self.W.shape)\n",
        "        self.dB = np.zeros(self.B.shape)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "        if self.P == 0:\n",
        "            dZ = np.delete(dZ,[0,H-1],axis=2)\n",
        "            dZ = np.delete(dZ,[0,W-1],axis=3)\n",
        "        else:\n",
        "            dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
        "            dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
        "            dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "            dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(OH):\n",
        "                    for col in range(OW):\n",
        "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "        for ch in range(F):\n",
        "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ"
      ],
      "metadata": {
        "id": "zCo1O-zcohnC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題2】小さな配列での2次元畳み込み層の実験"
      ],
      "metadata": {
        "id": "BdWwFfR38hEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN2 のフォワードを流す時の入力データ\n",
        "# (1,1,4,4)\n",
        "x = np.array([[[[ 1,  2,  3,  4],\n",
        "                [ 5,  6,  7,  8],\n",
        "                [ 9, 10, 11, 12],\n",
        "                [13, 14, 15, 16]]]])\n",
        "\n",
        "# (2,3,3)\n",
        "w = np.array([[[ 0.,  0.,  0.],\n",
        "               [ 0.,  1.,  0.],\n",
        "               [ 0., -1.,  0.]],\n",
        "\n",
        "              [[ 0.,  0.,  0.],\n",
        "               [ 0., -1.,  1.],\n",
        "               [ 0.,  0.,  0.]]])"
      ],
      "metadata": {
        "id": "oF4ecVvypFO7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = w.reshape(2, 1, 3, 3)\n",
        "simple_conv_2d = SimpleConv2d(F=2, C=1, FH=3, FW=3, P=0, S=1, initializer=SimpleInitializerConv2d(), optimizer=SGD(lr=0.01), activation=ReLU())\n",
        "simple_conv_2d.W = w\n",
        "A = simple_conv_2d.forward(x, True)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFspLS3dJsX5",
        "outputId": "ccf36201-cfbf-43a6-ea7b-3c7f46f352d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "da = np.array([[[[ -4,  -4], [ 10,  11]],[[  1,  -7],[  1, -11]]]])\n",
        "dZ = simple_conv_2d.backward(da,True)\n",
        "print(dZ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya5gzy8kPb6k",
        "outputId": "607e2869-3379-4cc0-9235-cea01b7f1008"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題3】2次元畳み込み後の出力サイズ"
      ],
      "metadata": {
        "id": "YN29Y0c6G-ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_conv_2d.output_shape2d(H=6,W=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WToSEi4QFZH",
        "outputId": "d68f0b3e-6745-40ad-95fc-fc55f778e95b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題4】最大プーリング層の作成"
      ],
      "metadata": {
        "id": "1NYqy2kaQQG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2D():\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "\n",
        "    def forward(self,A):\n",
        "        N, F, OH, OW = A.shape\n",
        "        PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "        self.params = N,F,OH,OW,self.P,PH,PW\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] = np.max(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "                        self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "        return self.PA\n",
        "\n",
        "    def backward(self,dA):\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        idx = self.Pindex[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i == idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ],
      "metadata": {
        "id": "bAN68RXiQPz7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題5】平均プーリングの作成"
      ],
      "metadata": {
        "id": "A38H76iPa8ON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AveragePool2D():\n",
        "    def __init__(self, P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.params = None\n",
        "\n",
        "    def forward(self, A):\n",
        "        N, F, OH, OW = A.shape\n",
        "        PH, PW = int(OH / self.P), int(OW / self.P)\n",
        "        self.params = N, F, OH, OW, self.P, PH, PW\n",
        "        self.PA = np.zeros([N, F, PH, PW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n, ch, row, col] = np.mean(A[n, ch, row * self.P:row * self.P + self.P, col * self.P:col * self.P + self.P])\n",
        "        return self.PA\n",
        "\n",
        "    def backward(self, dA):\n",
        "        N, F, OH, OW, PS, PH, PW = self.params\n",
        "        dP = np.zeros([N, F, OH, OW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        dP[n, ch, row * PS:row * PS + PS, col * PS:col * PS + PS] = dA[n, ch, row, col] / (PS * PS)\n",
        "        return dP"
      ],
      "metadata": {
        "id": "21Uh_mUibCH3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題6】平滑化"
      ],
      "metadata": {
        "id": "7sRKqEmAbKep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self,X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(len(X),-1)\n",
        "    def backward(self,X):\n",
        "        return X.reshape(self.shape)"
      ],
      "metadata": {
        "id": "wQ9NP0rGRQnA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題7】学習と推定"
      ],
      "metadata": {
        "id": "JyEzqA7ach8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scratch2dCNNClassifier():\n",
        "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
        "        self.NN = NN\n",
        "        self.CNN = CNN\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_batch = n_batch\n",
        "        self.verbose = verbose\n",
        "        self.log_loss = np.zeros(self.n_epoch)\n",
        "        self.log_acc = np.zeros(self.n_epoch)\n",
        "\n",
        "\n",
        "    def loss_function(self,y,yt):\n",
        "        delta = 1e-7\n",
        "        return -np.mean(yt*np.log(y+delta))\n",
        "    def accuracy(self,Z,Y):\n",
        "        return accuracy_score(Y,Z)\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred_data = X\n",
        "        for layer in range(len(self.CNN)):\n",
        "            pred_data = self.CNN[layer].forward(pred_data)\n",
        "        pred_data = flt.forward(pred_data)\n",
        "        for layer in range(len(self.NN)):\n",
        "            pred_data = self.NN[layer].forward(pred_data)\n",
        "        return np.argmax(pred_data,axis=1)\n",
        "\n",
        "    def fit(self, X, y, X_val=False, y_val=False):\n",
        "        for epoch in range(self.n_epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "            self.n_batches = get_mini_batch.n_batches\n",
        "            self.loss = 0\n",
        "            for mini_X_train, mini_y_train in get_mini_batch:\n",
        "                forward_data = mini_X_train\n",
        "                for layer in range(len(self.CNN)):\n",
        "                    forward_data = self.CNN[layer].forward(forward_data)\n",
        "                flt = Flatten()\n",
        "                forward_data = flt.forward(forward_data)\n",
        "                for layer in range(len(self.NN)):\n",
        "                    forward_data = self.NN[layer].forward(forward_data)\n",
        "                Z = forward_data\n",
        "                mini_y_train = mini_y_train.numpy()\n",
        "\n",
        "                backward_data = (Z - mini_y_train)/self.n_batch\n",
        "                for layer in range(len(self.NN)-1,-1,-1):\n",
        "                    backward_data = self.NN[layer].backward(backward_data)\n",
        "                backward_data = flt.backward(backward_data)\n",
        "                for layer in range(len(self.CNN)-1,-1,-1):\n",
        "                    backward_data = self.CNN[layer].backward(backward_data)\n",
        "                self.loss += self.loss_function(Z,mini_y_train)\n",
        "                if self.verbose:\n",
        "                    print('batch loss %f'%self.loss_function(Z,mini_y_train))\n",
        "            if self.verbose:\n",
        "                print(self.loss/len(get_mini_batch),self.accuracy(self.predict(X),np.argmax(y,axis=1)))\n",
        "            self.log_loss[epoch] = self.loss / self.n_batches\n",
        "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))"
      ],
      "metadata": {
        "id": "9H3F7XdLv_oE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "import numpy as np\n",
        "\n",
        "class FC:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes1からn_nodes2への全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            出力\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        A = X @ self.W + self.B\n",
        "        return self.activation.forward(A)\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            後ろから流れてきた勾配\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        dZ = self.activation.backward(dA)\n",
        "        self.dB = np.sum(dZ, axis=0)\n",
        "        self.dW = self.X.T @ dZ\n",
        "        dZ = dZ @ self.W.T\n",
        "        # 更新\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ\n",
        "class HeInitializer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        Weight initialization with He initialization.\n",
        "        \"\"\"\n",
        "        self.sigma = np.sqrt(2 / n_nodes1)  # He initialization\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        Bias initialization with zeros.\n",
        "        \"\"\"\n",
        "        return np.zeros(n_nodes2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm7Y97OgeAC0",
        "outputId": "f2662aa1-308d-48f4-f7a5-46d221eddab5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 1\n",
        "        self.HB = 1\n",
        "    def update(self, layer):\n",
        "        self.HW += layer.dW**2\n",
        "        self.HB += layer.dB**2\n",
        "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
        "        return layer"
      ],
      "metadata": {
        "id": "3RUtO_e7enxV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return np.zeros(n_nodes2)"
      ],
      "metadata": {
        "id": "BDt39z3le6AA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self, A):\n",
        "        self.Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1,1)\n",
        "        return self.Z\n",
        "    def backward(self, Y):\n",
        "        return self.Z - Y"
      ],
      "metadata": {
        "id": "Q2T9Wq0hfNNs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        self.n_batches = int(np.ceil(X.shape[0] / batch_size)) #ceilは切り上げ\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.idx = np.arange(self.X.shape[0]) #arangeで0からデータ数-1までの配列作成\n",
        "        np.random.shuffle(self.idx) #indexをシャッフル\n",
        "        for i in range(self.n_batches):\n",
        "            start = i * self.batch_size\n",
        "            end = start + self.batch_size\n",
        "            #indexのstartからendまでのデータを取得\n",
        "            #yieldで返すことでイテレータとして使用可能\n",
        "            yield self.X[self.idx[start:end]], self.y[self.idx[start:end]]"
      ],
      "metadata": {
        "id": "CEAV39_Jhytk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN = {\n",
        "    0:FC(1960, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "    1:FC(200, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "    2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
        "}\n",
        "CNN = {\n",
        "    0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(lr=0.01),activation=ReLU()),\n",
        "    1:MaxPool2D(2),\n",
        "}"
      ],
      "metadata": {
        "id": "5GslrHFgduHb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y_train_one_hot = F.one_hot(y_train, num_classes=10).float()"
      ],
      "metadata": {
        "id": "PPMGJJgxhmja"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=1,n_batch=20,verbose=True)"
      ],
      "metadata": {
        "id": "TnSRSkgrfe4o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "補足：ここでそのまま回したところ、毎回7時間程度かかり、エラーを吐いたり精度が非常に低かったため断念し、Torchを使うことにした。"
      ],
      "metadata": {
        "id": "2tI7-bbn-QS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# デバイス設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# データ変換とローダーの作成\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# モデル定義\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)  # 出力チャンネル数=32, カーネルサイズ=3\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) # 出力チャンネル数=64, カーネルサイズ=3\n",
        "        self.pool = nn.MaxPool2d(2)                  # プーリングサイズ=2\n",
        "        self.fc1 = nn.Linear(64 * 12 * 12, 128)        # 入力: 64チャンネル×12×12\n",
        "        self.fc2 = nn.Linear(128, 10)                # 出力: クラス数(10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# モデル・損失関数・オプティマイザ\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 学習ループ\n",
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # 順伝播と損失計算\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 勾配リセット、逆伝播、パラメータ更新\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# テスト\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU1aUurYlsWM",
        "outputId": "3d1f756a-6355-46a1-d96c-19c8a700c7cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1135\n",
            "Epoch [2/5], Loss: 0.0339\n",
            "Epoch [3/5], Loss: 0.0210\n",
            "Epoch [4/5], Loss: 0.0144\n",
            "Epoch [5/5], Loss: 0.0100\n",
            "Accuracy: 98.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題8】LeNet"
      ],
      "metadata": {
        "id": "CpHu5h9y4rL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# LeNetモデルの定義\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1)  # 畳み込み層1\n",
        "        self.relu = nn.ReLU()                                 # ReLU活性化関数\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)     # 最大プーリング\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)  # 畳み込み層2\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)                 # 平滑化後の全結合層1\n",
        "        self.fc2 = nn.Linear(120, 84)                        # 全結合層2\n",
        "        self.fc3 = nn.Linear(84, 10)                         # 全結合層3 (出力)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))  # 畳み込み -> ReLU\n",
        "        x = self.pool(x)              # プーリング\n",
        "        x = self.relu(self.conv2(x))  # 畳み込み -> ReLU\n",
        "        x = self.pool(x)              # プーリング\n",
        "        x = x.view(x.size(0), -1)     # 平滑化\n",
        "        x = self.relu(self.fc1(x))    # 全結合 -> ReLU\n",
        "        x = self.relu(self.fc2(x))    # 全結合 -> ReLU\n",
        "        x = self.fc3(x)               # 出力層\n",
        "        return x\n",
        "\n",
        "# MNISTデータセットの準備\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 平均0.5、標準偏差0.5で正規化\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# モデル、損失関数、最適化関数の定義\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# モデルのトレーニング\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # 順伝播\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 逆伝播と最適化\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# モデルの評価\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DB8A4Ky2kzr",
        "outputId": "de338557-03fa-4473-d68f-f4c7b09744b2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2643\n",
            "Epoch [2/10], Loss: 0.0746\n",
            "Epoch [3/10], Loss: 0.0537\n",
            "Epoch [4/10], Loss: 0.0421\n",
            "Epoch [5/10], Loss: 0.0344\n",
            "Epoch [6/10], Loss: 0.0282\n",
            "Epoch [7/10], Loss: 0.0256\n",
            "Epoch [8/10], Loss: 0.0218\n",
            "Epoch [9/10], Loss: 0.0187\n",
            "Epoch [10/10], Loss: 0.0151\n",
            "Test Accuracy: 98.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題9】有名な画像認識モデルの調査\n",
        "\n",
        "テキストに記載されているURLはnot foundになってしまい読み込めなかった。"
      ],
      "metadata": {
        "id": "8tmneRGl63Yb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題10】出力サイズとパラメータ数の計算"
      ],
      "metadata": {
        "id": "jmQltgHq7Dj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_output_size(input_size, filter_size, stride, padding):\n",
        "    \"\"\"\n",
        "    Calculate the output size of a convolutional layer.\n",
        "    Args:\n",
        "        input_size (tuple): Input dimensions (H, W).\n",
        "        filter_size (int): Size of the square filter.\n",
        "        stride (int): Stride of the convolution.\n",
        "        padding (int): Amount of padding (usually 0 or 'same').\n",
        "\n",
        "    Returns:\n",
        "        tuple: Output dimensions (H_out, W_out).\n",
        "    \"\"\"\n",
        "    H, W = input_size\n",
        "    H_out = (H - filter_size + 2 * padding) // stride + 1\n",
        "    W_out = (W - filter_size + 2 * padding) // stride + 1\n",
        "    return H_out, W_out\n",
        "\n",
        "def calculate_parameters(filter_size, input_channels, output_channels, include_bias=True):\n",
        "    \"\"\"\n",
        "    Calculate the number of parameters in a convolutional layer.\n",
        "    Args:\n",
        "        filter_size (int): Size of the square filter.\n",
        "        input_channels (int): Number of input channels.\n",
        "        output_channels (int): Number of output channels.\n",
        "        include_bias (bool): Whether to include bias parameters.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of parameters.\n",
        "    \"\"\"\n",
        "    filter_params = filter_size * filter_size * input_channels * output_channels\n",
        "    bias_params = output_channels if include_bias else 0\n",
        "    return filter_params + bias_params\n",
        "\n",
        "# 1st layer\n",
        "input_size_1 = (144, 144)\n",
        "filter_size_1 = 3\n",
        "stride_1 = 1\n",
        "padding_1 = 0\n",
        "input_channels_1 = 3\n",
        "output_channels_1 = 6\n",
        "\n",
        "output_size_1 = calculate_output_size(input_size_1, filter_size_1, stride_1, padding_1)\n",
        "parameters_1 = calculate_parameters(filter_size_1, input_channels_1, output_channels_1)\n",
        "\n",
        "# 2nd layer\n",
        "input_size_2 = (60, 60)\n",
        "filter_size_2 = 3\n",
        "stride_2 = 1\n",
        "padding_2 = 0\n",
        "input_channels_2 = 24\n",
        "output_channels_2 = 48\n",
        "\n",
        "output_size_2 = calculate_output_size(input_size_2, filter_size_2, stride_2, padding_2)\n",
        "parameters_2 = calculate_parameters(filter_size_2, input_channels_2, output_channels_2)\n",
        "\n",
        "# 3rd layer\n",
        "input_size_3 = (20, 20)\n",
        "filter_size_3 = 3\n",
        "stride_3 = 2\n",
        "padding_3 = 0\n",
        "input_channels_3 = 10\n",
        "output_channels_3 = 20\n",
        "\n",
        "output_size_3 = calculate_output_size(input_size_3, filter_size_3, stride_3, padding_3)\n",
        "parameters_3 = calculate_parameters(filter_size_3, input_channels_3, output_channels_3)\n",
        "\n",
        "print(\"1st layer:\")\n",
        "print(f\"Output size: {output_size_1}\")\n",
        "print(f\"Number of parameters: {parameters_1}\")\n",
        "\n",
        "print(\"\\n2nd layer:\")\n",
        "print(f\"Output size: {output_size_2}\")\n",
        "print(f\"Number of parameters: {parameters_2}\")\n",
        "\n",
        "print(\"\\n3rd layer:\")\n",
        "print(f\"Output size: {output_size_3}\")\n",
        "print(f\"Number of parameters: {parameters_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9rU1hdt2koT",
        "outputId": "aabf3d38-bbf3-4101-be3c-c49b8a8f7c8d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st layer:\n",
            "Output size: (142, 142)\n",
            "Number of parameters: 168\n",
            "\n",
            "2nd layer:\n",
            "Output size: (58, 58)\n",
            "Number of parameters: 10416\n",
            "\n",
            "3rd layer:\n",
            "Output size: (9, 9)\n",
            "Number of parameters: 1820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##【問題11】フィルタサイズに関する調査\n",
        "\n",
        "1. 3×3フィルタが一般的な理由\n",
        "\n",
        "* パラメータ数の削減: 大きなフィルタ（7×7など）と比較して、3×3フィルタは同等の受容野を持ちながら、はるかに少ないパラメータで実現る。例えば、7×7フィルタは49個のパラメータが必要ですが、3×3フィルタを3回重ねて適用すると、同等の受容野を9個のパラメータで実現できる。\n",
        "\n",
        "* 計算効率: 小さなフィルタを重ねて適用することで、同じ計算量でより深いネットワークを構築できる。これにより、より複雑な特徴の抽出が可能になる。\n",
        "\n",
        "* 非線形性の導入: フィルタを重ねることで、各層間に活性化関数（ReLUなど）を挿入できるため、ネットワークの表現力が向上する。\n",
        "---\n",
        "2. 1×1フィルタの効果\n",
        "\n",
        "1×1畳み込み（ポイントワイズ畳み込み）は一見すると直感的ではないが……\n",
        "\n",
        "* チャネル数の調整: 1×1畳み込みは、入力テンソルのチャネル数を増減させることができる。これにより、ネットワークの幅（チャネル数）を効率的に制御できる。\n",
        "\n",
        "* 特徴量の非線形な変換: 1×1畳み込みは、各空間位置で異なるチャネル間の線形結合と非線形活性化を可能にする。これは、特徴量の再校正や情報の圧縮に役立つ。\n",
        "\n",
        "* 計算量の削減: Inception moduleやResNetなどの高度なアーキテクチャでは、1×1畳み込みを使用して計算量を削減しながら、ネットワークの表現力を維持している。\n",
        "---\n",
        "これらの理由により、現代のCNNアーキテクチャでは3×3と1×1のフィルタが主流となっている。フィルタサイズの選択は、モデルの性能、計算効率、パラメータ数のバランスを取る上で重要な設計要素である。\n",
        "\n",
        "また、3×3フィルタに関しては、数学的な観点からも興味深い特性がある。3×3は最小の対称的な正方形フィルタであり、任意の大きな畳み込みフィルタを3×3フィルタの重ね合わせで近似できることが証明されている。つまり、7×7や5×5のフィルタを3×3のフィルタで置き換えても、ほぼ同等の特徴抽出が可能である。\n",
        "1×1フィルタについては、特にGoogleのネットワークアーキテクチャ研究（Inception moduleなど）で大きな役割を果たした。チャネル間の情報の再構成や、計算量の大幅な削減を可能にする、いわば「次元変換」の役割を果たす。"
      ],
      "metadata": {
        "id": "ycOSPSNV8mPi"
      }
    }
  ]
}